{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f49d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 1) EMD 경계 읽기 & 키 생성\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼=['geometry']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 209\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# ================== 데이터 로드/피처 구성 ==================\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[INFO] 1) EMD 경계 읽기 & 키 생성\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m emd = \u001b[43mresolve_emd_keys_from_shp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSHP_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m BOUNDARY_HAS_CODE = \u001b[33m\"\u001b[39m\u001b[33mADM_CODE_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m emd.columns\n\u001b[32m    211\u001b[39m BOUNDARY_HAS_NAME = \u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m emd.columns\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36mresolve_emd_keys_from_shp\u001b[39m\u001b[34m(shp_path)\u001b[39m\n\u001b[32m    109\u001b[39m     g[\u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m] = g[name_col].astype(\u001b[38;5;28mstr\u001b[39m).map(standardize_emd_name)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mADM_CODE_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m g.columns) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m g.columns):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(g.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    112\u001b[39m g[\u001b[33m\"\u001b[39m\u001b[33marea_km2\u001b[39m\u001b[33m\"\u001b[39m] = g.geometry.area / \u001b[32m1_000_000.0\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "\u001b[31mRuntimeError\u001b[39m: 읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼=['geometry']"
     ]
    }
   ],
   "source": [
    "\n",
    "# LightGBM\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# LightGBM 전용: Cheonan EMD-level population modeling (완전 실행형)\n",
    "# - shp(.shx 누락 자동복구), POI(학교/버스/병원), 주민등록 인구(읍면동, 2020~2024) 연도 프레임\n",
    "# - YouthIndex/SeniorCareIndex 합성지표 포함\n",
    "# - GroupKFold(연도 홀드아웃) 평가, 중요도/OOF/최종모델 저장\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings, re, os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd, numpy as np, geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from lightgbm import LGBMRegressor\n",
    "import joblib\n",
    "\n",
    "# ================== 경로/상수 ==================\n",
    "BASE = Path(r\"C:\\공모전\\2025천안\")\n",
    "\n",
    "OUT  = BASE / \"outputs\" / \"LightGBM\"; OUT.mkdir(parents=True, exist_ok=True)\n",
    "SHP_PATH = BASE / \"천안시경계(24).shp\"   # .shx 없어도 자동 복구 시도\n",
    "POP_DIR  = BASE / \"주민등록인구\"\n",
    "POP_FILE = BASE / \"시군구별 이동자\" / \"202001_202412_주민등록인구및세대현황_월간.csv\"\n",
    "POP_INPUT_IS_FILE = True# 보유 중인 읍면동 인구 표 폴더\n",
    "SCHOOL_CSV   = BASE / \"초중등학교 데이터\" / \"전국초중등학교위치표준데이터.csv\"\n",
    "BUS_CSV      = BASE / \"버스정류장 위치정보\" / \"국토교통부_전국 버스정류장 위치정보.csv\"\n",
    "HOSPITAL_CSV = BASE / \"병원정보서비스\" / \"병원정보서비스.csv\"\n",
    "\n",
    "YEARS = [2020, 2021, 2022, 2023, 2024]\n",
    "DEFAULT_PROJ = \"EPSG:5179\"  # Korea 2000 / Unified CS\n",
    "\n",
    "TARGET_CANDIDATES = [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"총인구\",\"population\",\"total_pop\"]\n",
    "\n",
    "# shp 읽을 때 .shx 자동 복구 허용\n",
    "os.environ[\"SHAPE_RESTORE_SHX\"] = \"YES\"\n",
    "\n",
    "# 이름/코드 컬럼 후보(경계/인구 모두 대응)\n",
    "EMD_NAME_CANDS = [\n",
    "    \"EMD_NM\",\"EMD_KOR_NM\",\"EMD_NAME\",\"EMD_NM_KR\",\"EMD_NM_KOR\",\"EMD_NM_KO\",\n",
    "    \"읍면동\",\"읍면동명\",\"행정동\",\"행정동명\",\"법정동\",\"법정동명\",\"adm_nm\",\"adm_dr_nm\",\"NAME\",\"name\",\"동리명\"\n",
    "]\n",
    "EMD_CODE_CANDS = [\n",
    "    \"EMD_CD\",\"EMDCD\",\"ADM_CD\",\"adm_cd\",\"법정동코드\",\"행정동코드\",\"법정리코드\",\"법정동코드(10자리)\",\"HCODE\",\"CODE\"\n",
    "]\n",
    "POP_NAME_CANDS = [\"읍면동\",\"읍면동명\",\"행정동\",\"행정동명\",\"법정동\",\"법정동명\",\"adm_nm\",\"EMD_NM\",\"동리명\",\"NAME\",\"name\"]\n",
    "POP_CODE_CANDS = [\"행정동코드\",\"법정동코드\",\"EMD_CD\",\"adm_cd\",\"CODE\",\"HCODE\"]\n",
    "\n",
    "# ================== 유틸 함수 ==================\n",
    "def pick_col(cols, cands):\n",
    "    \"\"\"정확일치 → 공백/대소문자 무시 → 부분포함 순으로 첫 컬럼 반환\"\"\"\n",
    "    for c in cands:\n",
    "        if c in cols: return c\n",
    "    norm = {re.sub(r\"\\s+\",\"\",c).lower(): c for c in cols}\n",
    "    for cand in cands:\n",
    "        key = re.sub(r\"\\s+\",\"\",cand).lower()\n",
    "        if key in norm: return norm[key]\n",
    "    for c in cols:\n",
    "        for cand in cands:\n",
    "            if re.sub(r\"\\s+\",\"\",cand).lower() in re.sub(r\"\\s+\",\"\",c).lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def standardize_emd_name(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r\"\\s+\",\"\", s)\n",
    "    # 필요하면 접두부(천안시동남구/서북구) 제거 등 커스텀 룰 추가 가능\n",
    "    return s\n",
    "\n",
    "def normalize_adm_code(series, zfill=10):\n",
    "    \"\"\"숫자만 남겨 10자리(법정동코드 관용) zero-fill\"\"\"\n",
    "    return series.astype(str).str.replace(r\"\\D\",\"\", regex=True).str.zfill(zfill)\n",
    "\n",
    "def guess_emd_name_col(gdf: gpd.GeoDataFrame):\n",
    "    \"\"\"한글+동/읍/면/리로 끝나는 비율 높은 문자열 컬럼 자동 후보\"\"\"\n",
    "    cand=[]\n",
    "    for c in gdf.columns:\n",
    "        if gdf[c].dtype == \"object\":\n",
    "            s = gdf[c].astype(str).head(200)\n",
    "            ratio = s.str.contains(r\"(동|읍|면|리)$\").mean()\n",
    "            if ratio >= 0.2:\n",
    "                cand.append((ratio, c))\n",
    "    if cand:\n",
    "        cand.sort(reverse=True)\n",
    "        return cand[0][1]\n",
    "    return None\n",
    "\n",
    "def read_shp_with_restore(shp_path: str, default_crs=DEFAULT_PROJ):\n",
    "    import fiona\n",
    "    with fiona.Env(SHAPE_RESTORE_SHX=\"YES\"):\n",
    "        g = gpd.read_file(shp_path)\n",
    "    if g.crs is None:\n",
    "        g = g.set_crs(default_crs, allow_override=True)\n",
    "    return g\n",
    "\n",
    "def resolve_emd_keys_from_shp(shp_path: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"경계에서 이름/코드 표준 키 생성 + 면적 km² 추가\"\"\"\n",
    "    g = read_shp_with_restore(shp_path)\n",
    "    code_col = pick_col(g.columns, EMD_CODE_CANDS)\n",
    "    name_col = pick_col(g.columns, EMD_NAME_CANDS) or guess_emd_name_col(g)\n",
    "    if code_col is not None:\n",
    "        g[\"ADM_CODE_STD\"] = normalize_adm_code(g[code_col])\n",
    "    if name_col is not None:\n",
    "        g[\"EMD_NAME_STD\"] = g[name_col].astype(str).map(standardize_emd_name)\n",
    "    if (\"ADM_CODE_STD\" not in g.columns) and (\"EMD_NAME_STD\" not in g.columns):\n",
    "        raise RuntimeError(f\"읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼={list(g.columns)}\")\n",
    "    g[\"area_km2\"] = g.geometry.area / 1_000_000.0\n",
    "    return g\n",
    "\n",
    "def detect_latlon(df: pd.DataFrame):\n",
    "    lat_cands = [\"위도\",\"lat\",\"latitude\",\"Y\",\"y\",\"WGS84위도\",\"Y좌표\",\"Y좌표(WGS84)\"]\n",
    "    lon_cands = [\"경도\",\"lon\",\"longitude\",\"X\",\"x\",\"WGS84경도\",\"X좌표\",\"X좌표(WGS84)\"]\n",
    "    lat = pick_col(df.columns, lat_cands)\n",
    "    lon = pick_col(df.columns, lon_cands)\n",
    "    return lat, lon\n",
    "\n",
    "def to_points(df: pd.DataFrame, lat: str, lon: str, crs=\"EPSG:4326\") -> gpd.GeoDataFrame:\n",
    "    d = df.dropna(subset=[lat, lon]).copy()\n",
    "    d[lat] = pd.to_numeric(d[lat], errors=\"coerce\")\n",
    "    d[lon] = pd.to_numeric(d[lon], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[lat, lon])\n",
    "    return gpd.GeoDataFrame(d, geometry=gpd.points_from_xy(d[lon], d[lat]), crs=crs)\n",
    "\n",
    "def project_like(g: gpd.GeoDataFrame, like: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    if g.crs is None: g = g.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "    if like.crs is None: like = like.set_crs(DEFAULT_PROJ, allow_override=True)\n",
    "    if g.crs != like.crs: g = g.to_crs(like.crs)\n",
    "    return g\n",
    "\n",
    "def sjoin_counts_and_nearest(points_gdf, emd, prefix):\n",
    "    \"\"\"EMD 내 포함 카운트, km²당 밀도, 최근접거리(km) 및 로그보조\"\"\"\n",
    "    emd_cent = emd.copy(); emd_cent[\"centroid\"] = emd.geometry.centroid\n",
    "    emd_cent = emd_cent.set_geometry(\"centroid\")\n",
    "    # 최근접 거리\n",
    "    if len(points_gdf) > 0:\n",
    "        nn = gpd.sjoin_nearest(emd_cent, points_gdf[[\"geometry\"]], how=\"left\", distance_col=f\"{prefix}_nearest_m\")\n",
    "        near = nn[[f\"{prefix}_nearest_m\"]].reindex(emd.index)\n",
    "    else:\n",
    "        near = pd.DataFrame({f\"{prefix}_nearest_m\":[np.nan]*len(emd)}, index=emd.index)\n",
    "    # 포함 카운트\n",
    "    if len(points_gdf) > 0:\n",
    "        jj = gpd.sjoin(emd, points_gdf[[\"geometry\"]], how=\"left\", predicate=\"contains\")\n",
    "        counts = jj.groupby(jj.index).size().reindex(emd.index).fillna(0).astype(int)\n",
    "    else:\n",
    "        counts = pd.Series(0, index=emd.index, dtype=int)\n",
    "    out = pd.DataFrame(index=emd.index)\n",
    "    out[f\"{prefix}_count\"] = counts\n",
    "    area = (emd.geometry.area/1_000_000.0).replace(0, np.nan)\n",
    "    out[f\"{prefix}_dens_km2\"] = out[f\"{prefix}_count\"] / area\n",
    "    out[f\"{prefix}_dens_log1p\"] = np.log1p(out[f\"{prefix}_dens_km2\"])\n",
    "    out = pd.concat([out, near], axis=1)\n",
    "    out[f\"{prefix}_nearest_km\"] = out[f\"{prefix}_nearest_m\"] / 1000.0\n",
    "    out[f\"{prefix}_nearest_log1p\"] = np.log1p(out[f\"{prefix}_nearest_km\"])\n",
    "    return out\n",
    "\n",
    "def zscore(s: pd.Series):\n",
    "    return (s - s.mean()) / (s.std(ddof=0) + 1e-9)\n",
    "\n",
    "def read_any_table(p: Path) -> pd.DataFrame:\n",
    "    if p.suffix.lower() == \".csv\":\n",
    "        for enc in (\"utf-8-sig\",\"cp949\",\"euc-kr\"):\n",
    "            try: return pd.read_csv(p, encoding=enc)\n",
    "            except UnicodeDecodeError: continue\n",
    "        return pd.read_csv(p)\n",
    "    else:\n",
    "        return pd.read_excel(p)\n",
    "\n",
    "def find_pop_files(pop_dir: Path):\n",
    "    pats=[r\".*인구.*\\.(csv|xlsx)$\", r\".*주민.*\\.(csv|xlsx)$\", r\".*세대.*\\.(csv|xlsx)$\"]\n",
    "    files=[]\n",
    "    for fp in pop_dir.glob(\"**/*\"):\n",
    "        if fp.is_file() and any(re.match(p, fp.name, flags=re.I) for p in pats):\n",
    "            files.append(fp)\n",
    "    return files\n",
    "\n",
    "def coerce_ym(s):\n",
    "    if pd.isna(s): return (None,None)\n",
    "    t=str(s).strip().replace(\".\",\"\").replace(\"-\",\"\").replace(\"/\",\"\")\n",
    "    if len(t)>=6 and t[:6].isdigit(): return (int(t[:4]), int(t[4:6]))\n",
    "    if len(t)==4 and t.isdigit(): return (int(t),12)\n",
    "    return (None,None)\n",
    "\n",
    "def resolve_keys_from_pop(df_in: pd.DataFrame):\n",
    "    \"\"\"인구 표에서 이름/코드 표준 키 생성(없으면 패턴으로 이름 유추)\"\"\"\n",
    "    df = df_in.copy()\n",
    "    code_col = pick_col(df.columns, POP_CODE_CANDS)\n",
    "    name_col = pick_col(df.columns, POP_NAME_CANDS)\n",
    "    if code_col is not None:\n",
    "        df[\"ADM_CODE_STD\"] = normalize_adm_code(df[code_col])\n",
    "    if name_col is not None:\n",
    "        df[\"EMD_NAME_STD\"] = df[name_col].astype(str).map(standardize_emd_name)\n",
    "    if (\"ADM_CODE_STD\" not in df.columns) and (\"EMD_NAME_STD\" not in df.columns):\n",
    "        # 값 패턴으로 이름 추정\n",
    "        for c in df.columns:\n",
    "            if df[c].dtype == \"object\":\n",
    "                s = df[c].astype(str).head(200)\n",
    "                if s.str.contains(r\"(동|읍|면|리)$\").mean() >= 0.2:\n",
    "                    df[\"EMD_NAME_STD\"] = df[c].astype(str).map(standardize_emd_name)\n",
    "                    break\n",
    "    return df\n",
    "\n",
    "# ================== 데이터 로드/피처 구성 ==================\n",
    "print(\"[INFO] 1) EMD 경계 읽기 & 키 생성\")\n",
    "emd = resolve_emd_keys_from_shp(str(SHP_PATH))\n",
    "BOUNDARY_HAS_CODE = \"ADM_CODE_STD\" in emd.columns\n",
    "BOUNDARY_HAS_NAME = \"EMD_NAME_STD\" in emd.columns\n",
    "idx_col = \"EMD_NAME_STD\" if BOUNDARY_HAS_NAME else \"ADM_CODE_STD\"\n",
    "emd = emd.set_index(idx_col, drop=False)\n",
    "\n",
    "print(\"[DEBUG] EMD columns:\", list(emd.columns))\n",
    "print(\"[DEBUG] has code:\", BOUNDARY_HAS_CODE, \"has name:\", BOUNDARY_HAS_NAME)\n",
    "\n",
    "print(\"[INFO] 2) POI 읽기 → 포인트 변환 → 경계 좌표계로 투영\")\n",
    "def read_poi(csv_path: Path, emd):\n",
    "    if not csv_path.exists():\n",
    "        print(f\"[WARN] POI 파일 없음: {csv_path.name}\")\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    try: df = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "    except UnicodeDecodeError: df = pd.read_csv(csv_path, encoding=\"cp949\")\n",
    "    lat, lon = detect_latlon(df)\n",
    "    if not (lat and lon):\n",
    "        print(f\"[WARN] 위경도 컬럼 자동탐색 실패 → 빈 처리: {csv_path.name}\")\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    g = to_points(df, lat, lon, crs=\"EPSG:4326\")\n",
    "    return project_like(g, emd)\n",
    "\n",
    "g_school = read_poi(SCHOOL_CSV, emd)\n",
    "g_bus    = read_poi(BUS_CSV, emd)\n",
    "g_hosp   = read_poi(HOSPITAL_CSV, emd)\n",
    "\n",
    "print(\"[INFO] 3) EMD별 정적 피처(카운트/밀도/최근접거리) + 합성지표\")\n",
    "f_school = sjoin_counts_and_nearest(g_school, emd, \"school\")\n",
    "f_bus    = sjoin_counts_and_nearest(g_bus, emd, \"bus\")\n",
    "f_hosp   = sjoin_counts_and_nearest(g_hosp, emd, \"hosp\")\n",
    "feat_static = pd.concat([f_school, f_bus, f_hosp], axis=1)\n",
    "\n",
    "feat_static[\"school_z\"] = zscore(feat_static[\"school_dens_km2\"].fillna(0))\n",
    "feat_static[\"bus_z\"]    = zscore(feat_static[\"bus_dens_km2\"].fillna(0))\n",
    "feat_static[\"hosp_z\"]   = zscore(feat_static[\"hosp_dens_km2\"].fillna(0))\n",
    "\n",
    "# 합성지표(도메인 priors): YouthIndex & SeniorCareIndex\n",
    "# - YouthIndex = 0.5*학교 + 0.3*버스 + 0.2*병원\n",
    "# - SeniorCareIndex = 0.6*병원 + 0.3*버스 + 0.1*학교\n",
    "feat_static[\"YouthIndex\"]      = 0.5*feat_static[\"school_z\"] + 0.3*feat_static[\"bus_z\"] + 0.2*feat_static[\"hosp_z\"]\n",
    "feat_static[\"SeniorCareIndex\"] = 0.6*feat_static[\"hosp_z\"]  + 0.3*feat_static[\"bus_z\"] + 0.1*feat_static[\"school_z\"]\n",
    "feat_static[\"area_km2\"] = emd[\"area_km2\"]\n",
    "\n",
    "print(\"[INFO] 4) 인구 표 읽기/연도화 (월 자료면 최신월, 없으면 연 스냅샷)\")\n",
    "def build_population(pop_dir: Path, years: list):\n",
    "    files = find_pop_files(pop_dir)\n",
    "    if not files:\n",
    "        print(f\"[WARN] 인구 파일이 없습니다: {pop_dir}\")\n",
    "        return pd.DataFrame()\n",
    "    frames=[]\n",
    "    for p in files:\n",
    "        df = read_any_table(p)\n",
    "        df = resolve_keys_from_pop(df)\n",
    "        # 연/월 추출\n",
    "        ym_col = pick_col(df.columns, [\"기준년월\",\"년월\",\"연월\",\"yyyymm\",\"기준일자\",\"date\",\"집계년월\"])\n",
    "        year_col = pick_col(df.columns, [\"연도\",\"년도\",\"year\",\"Year\"])\n",
    "        month_col= pick_col(df.columns, [\"월\",\"month\",\"Month\"])\n",
    "        if ym_col:\n",
    "            ym=df[ym_col].map(coerce_ym); df[\"__year__\"]=[y for y,_ in ym]; df[\"__month__\"]=[m for _,m in ym]\n",
    "        elif year_col:\n",
    "            df[\"__year__\"]=pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "            df[\"__month__\"]=pd.to_numeric(df[month_col], errors=\"coerce\") if month_col else 12\n",
    "        else:\n",
    "            m=re.search(r\"(20\\d{2})(0[1-9]|1[0-2])\", p.stem)\n",
    "            if m: df[\"__year__\"]=int(m.group(1)); df[\"__month__\"]=int(m.group(2))\n",
    "            else:\n",
    "                m2=re.search(r\"(20\\d{2})\", p.stem)\n",
    "                df[\"__year__\"]=int(m2.group(1)) if m2 else np.nan; df[\"__month__\"]=12\n",
    "\n",
    "        # 타깃 후보 준비\n",
    "        total = pick_col(df.columns, [\"총인구\",\"인구\",\"총인구수\",\"population\",\"total_pop\"])\n",
    "        aged  = pick_col(df.columns, [\"65세이상\",\"65세이상인구\",\"고령인구\",\"over65\"])\n",
    "        aging = pick_col(df.columns, [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"ratio_65\"])\n",
    "        keep = [\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\",\"__month__\"] + [c for c in [total, aged, aging] if c]\n",
    "        df2 = df[keep].copy()\n",
    "        frames.append(df2)\n",
    "\n",
    "    pop = pd.concat(frames, ignore_index=True)\n",
    "    pop = pop.dropna(subset=[\"__year__\"])\n",
    "    pop = pop[pop[\"__year__\"].isin(years)]\n",
    "    # 월 자료면 최신월(연말/가장 최근) 선택\n",
    "    pop = pop.sort_values([\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\",\"__month__\"])\n",
    "    pop = pop.groupby([\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\"], as_index=False).tail(1)\n",
    "\n",
    "    # 고령화율 계산(없으면)\n",
    "    if \"aging_rate\" not in pop.columns:\n",
    "        tcol = pick_col(pop.columns, [\"총인구\",\"인구\",\"총인구수\",\"population\",\"total_pop\"])\n",
    "        acol = pick_col(pop.columns, [\"65세이상\",\"65세이상인구\",\"고령인구\",\"over65\"])\n",
    "        if tcol and acol:\n",
    "            pop[\"aging_rate\"] = pd.to_numeric(pop[acol], errors=\"coerce\")/pd.to_numeric(pop[tcol], errors=\"coerce\")\n",
    "\n",
    "    pop = pop.rename(columns={\"__year__\":\"year\"})\n",
    "    return pop\n",
    "\n",
    "pop_yearly = build_population(POP_DIR, YEARS)\n",
    "if pop_yearly.empty:\n",
    "    raise SystemExit(\"[ERROR] 인구 데이터가 비었습니다. POP_DIR에 파일을 넣고 다시 실행하세요.\")\n",
    "\n",
    "print(\"[INFO] 5) 연패널 구성(정적 피처 연도별 복제) + 병합\")\n",
    "panel=[]\n",
    "for y in YEARS:\n",
    "    tmp = feat_static.copy()\n",
    "    tmp[\"year\"] = y\n",
    "    # 병합 키 컬럼(이름/코드) 동시 보유\n",
    "    if \"EMD_NAME_STD\" in emd.columns: tmp[\"EMD_NAME_STD\"] = emd[\"EMD_NAME_STD\"]\n",
    "    if \"ADM_CODE_STD\" in emd.columns: tmp[\"ADM_CODE_STD\"] = emd[\"ADM_CODE_STD\"]\n",
    "    panel.append(tmp.reset_index(drop=True))\n",
    "panel = pd.concat(panel, axis=0)\n",
    "\n",
    "# 병합 키 결정 (코드 우선, 그다음 이름)\n",
    "POP_HAS_CODE = \"ADM_CODE_STD\" in pop_yearly.columns\n",
    "POP_HAS_NAME = \"EMD_NAME_STD\" in pop_yearly.columns\n",
    "BOUNDARY_HAS_CODE = \"ADM_CODE_STD\" in panel.columns\n",
    "BOUNDARY_HAS_NAME = \"EMD_NAME_STD\" in panel.columns\n",
    "\n",
    "if BOUNDARY_HAS_CODE and POP_HAS_CODE:\n",
    "    key = \"ADM_CODE_STD\"\n",
    "elif BOUNDARY_HAS_NAME and POP_HAS_NAME:\n",
    "    key = \"EMD_NAME_STD\"\n",
    "else:\n",
    "    key = \"EMD_NAME_STD\" if POP_HAS_NAME else \"ADM_CODE_STD\"\n",
    "\n",
    "data = pop_yearly.merge(panel, on=[key,\"year\"], how=\"left\")\n",
    "\n",
    "# ================== 타깃/피처 준비 (X, y, groups) ==================\n",
    "tgt=None\n",
    "for c in TARGET_CANDIDATES:\n",
    "    if c in data.columns:\n",
    "        tgt=c; break\n",
    "if tgt is None:\n",
    "    raise SystemExit(\"[ERROR] 타깃 컬럼(고령화율/총인구 등)이 데이터에 없습니다.\")\n",
    "\n",
    "feature_cols = [\n",
    "    # 밀도/거리형\n",
    "    \"school_dens_km2\",\"bus_dens_km2\",\"hosp_dens_km2\",\n",
    "    \"school_dens_log1p\",\"bus_dens_log1p\",\"hosp_dens_log1p\",\n",
    "    \"school_nearest_km\",\"bus_nearest_km\",\"hosp_nearest_km\",\n",
    "    \"school_nearest_log1p\",\"bus_nearest_log1p\",\"hosp_nearest_log1p\",\n",
    "    # 합성지표\n",
    "    \"YouthIndex\",\"SeniorCareIndex\",\n",
    "    # 면적\n",
    "    \"area_km2\",\n",
    "]\n",
    "feature_cols = [c for c in feature_cols if c in data.columns]\n",
    "for c in feature_cols:\n",
    "    data[c] = pd.to_numeric(data[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "y = pd.to_numeric(data[tgt], errors=\"coerce\")\n",
    "mask = ~y.isna()\n",
    "data = data.loc[mask].reset_index(drop=True)\n",
    "y = y.loc[mask].reset_index(drop=True)\n",
    "X = data[feature_cols].copy()\n",
    "groups = data[\"year\"].astype(int)\n",
    "\n",
    "print(f\"[INFO] Target={tgt} | X shape={X.shape} | years={sorted(groups.unique())}\")\n",
    "print(\"[DEBUG] Features:\", feature_cols)\n",
    "\n",
    "# ================== 학습/평가 ==================\n",
    "def run_cv(model_name, model, X, y, groups):\n",
    "    gkf=GroupKFold(n_splits=len(YEARS))\n",
    "    oof=np.full(len(y), np.nan); rows=[]\n",
    "    for i,(tr,va) in enumerate(gkf.split(X,y,groups),1):\n",
    "        model.fit(X.iloc[tr], y.iloc[tr])\n",
    "        pred=model.predict(X.iloc[va])\n",
    "        oof[va]=pred\n",
    "        r2=r2_score(y.iloc[va],pred); mae=mean_absolute_error(y.iloc[va],pred); rmse=mean_squared_error(y.iloc[va],pred,squared=False)\n",
    "        yr=int(groups.iloc[va].iloc[0]); rows.append({\"fold\":i,\"valid_year\":yr,\"R2\":r2,\"MAE\":mae,\"RMSE\":rmse})\n",
    "        print(f\"[{model_name}] Fold{i} (valid {yr})  R2={r2:.3f}  MAE={mae:.3f}  RMSE={rmse:.3f}\")\n",
    "    pd.DataFrame(rows).to_csv(OUT/f\"cv_{model_name}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 중요도 저장 (Permutation + 내장 중요도)\n",
    "    try:\n",
    "        imp=permutation_importance(model, X, y, n_repeats=10, random_state=42)\n",
    "        pd.DataFrame({\"feature\":X.columns,\n",
    "                      \"perm_importance_mean\":imp.importances_mean,\n",
    "                      \"perm_importance_std\":imp.importances_std})\\\n",
    "          .sort_values(\"perm_importance_mean\", ascending=False)\\\n",
    "          .to_csv(OUT/f\"feat_importance_perm_{model_name}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] permutation importance 실패:\", e)\n",
    "    try:\n",
    "        fi = getattr(model, \"feature_importances_\", None)\n",
    "        if fi is not None:\n",
    "            pd.DataFrame({\"feature\":X.columns, \"lgbm_importance\":fi})\\\n",
    "              .sort_values(\"lgbm_importance\", ascending=False)\\\n",
    "              .to_csv(OUT/f\"feat_importance_{model_name}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] 내장 중요도 저장 실패:\", e)\n",
    "\n",
    "    # OOF 저장\n",
    "    oof_df=data[[(\"EMD_NAME_STD\" if \"EMD_NAME_STD\" in data.columns else None), (\"ADM_CODE_STD\" if \"ADM_CODE_STD\" in data.columns else None), \"year\"]].copy()\n",
    "    # 위 줄에서 None 컬럼이 섞이지 않도록 정리\n",
    "    ocols=[c for c in [\"EMD_NAME_STD\",\"ADM_CODE_STD\",\"year\"] if c in oof_df.columns]\n",
    "    oof_df=oof_df[ocols]\n",
    "    oof_df[\"y_true\"]=y.values; oof_df[\"y_pred\"]=oof\n",
    "    oof_df.to_csv(OUT/f\"oof_{model_name}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# LightGBM 하이퍼파라미터(합리적 기본값)\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=1600,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    max_depth=-1,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_alpha=1e-2,\n",
    "    reg_lambda=1e-1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "run_cv(\"LightGBM\", lgbm, X, y, groups)\n",
    "\n",
    "# ================== 전체 학습 & 저장 ==================\n",
    "lgbm.fit(X,y)\n",
    "joblib.dump(lgbm, OUT/\"final_lgbm.pkl\")\n",
    "\n",
    "data_out = data[[c for c in [\"EMD_NAME_STD\",\"ADM_CODE_STD\",\"year\",tgt]+feature_cols if c in data.columns]].copy()\n",
    "data_out.to_csv(OUT/\"model_input_panel.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"[DONE] LightGBM outputs saved →\", OUT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f538cf48",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "data DataFrame이 없습니다. (경계/POI/인구) 전처리 블록을 먼저 실행해 'data'를 만든 뒤 다시 실행하세요.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m data DataFrame이 없습니다. (경계/POI/인구) 전처리 블록을 먼저 실행해 'data'를 만든 뒤 다시 실행하세요.\n"
     ]
    }
   ],
   "source": [
    "# === XGBoost 실행 전에 꼭 넣는 '드롭인 가드' ===\n",
    "# (전처리에서 'data'를 만든 뒤 실행해야 합니다)\n",
    "import os, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# 출력 폴더 기본값\n",
    "if 'OUT' not in globals():\n",
    "    OUT = Path(r\"C:\\공모전\\2025천안\\outputs\\XGBoost\")\n",
    "    OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 전처리 산출물 'data'가 없으면 중단\n",
    "if 'data' not in globals():\n",
    "    raise SystemExit(\"data DataFrame이 없습니다. (경계/POI/인구) 전처리 블록을 먼저 실행해 'data'를 만든 뒤 다시 실행하세요.\")\n",
    "\n",
    "# 교차검증용 연도 리스트\n",
    "if 'YEARS' not in globals():\n",
    "    YEARS = sorted(pd.unique(data['year']).astype(int).tolist())\n",
    "\n",
    "# 타깃 자동 선택\n",
    "TARGET_CANDIDATES = [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"총인구\",\"population\",\"total_pop\"]\n",
    "if 'tgt' not in globals():\n",
    "    tgt = next((c for c in TARGET_CANDIDATES if c in data.columns), None)\n",
    "    if tgt is None:\n",
    "        raise SystemExit(\"타깃 컬럼(고령화율/총인구 등)을 data에서 찾지 못했습니다.\")\n",
    "\n",
    "# 피처 목록(없으면 자동 축소)\n",
    "if 'feature_cols' not in globals():\n",
    "    base_feats = [\n",
    "        \"school_dens_km2\",\"bus_dens_km2\",\"hosp_dens_km2\",\n",
    "        \"school_dens_log1p\",\"bus_dens_log1p\",\"hosp_dens_log1p\",\n",
    "        \"school_nearest_km\",\"bus_nearest_km\",\"hosp_nearest_km\",\n",
    "        \"school_nearest_log1p\",\"bus_nearest_log1p\",\"hosp_nearest_log1p\",\n",
    "        \"YouthIndex\",\"SeniorCareIndex\",\"area_km2\"\n",
    "    ]\n",
    "    feature_cols = [c for c in base_feats if c in data.columns]\n",
    "\n",
    "# 결측/형 변환\n",
    "for c in feature_cols:\n",
    "    data[c] = pd.to_numeric(data[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "y = pd.to_numeric(data[tgt], errors=\"coerce\")\n",
    "mask = ~y.isna()\n",
    "data = data.loc[mask].reset_index(drop=True)\n",
    "y = y.loc[mask].reset_index(drop=True)\n",
    "\n",
    "\n",
    "X = data[feature_cols].copy()\n",
    "groups = data[\"year\"].astype(int)\n",
    "# === 드롭인 가드 끝 ===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80210fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] EMD 경계 읽기\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼=['geometry']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 212\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# 데이터 로드 & 피처 생성\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[INFO] EMD 경계 읽기\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m emd = \u001b[43mresolve_emd_keys_from_shp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSHP_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m BOUNDARY_HAS_CODE = \u001b[33m\"\u001b[39m\u001b[33mADM_CODE_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m emd.columns\n\u001b[32m    214\u001b[39m BOUNDARY_HAS_NAME = \u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m emd.columns\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mresolve_emd_keys_from_shp\u001b[39m\u001b[34m(shp_path)\u001b[39m\n\u001b[32m    112\u001b[39m     g[\u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m] = g[name_col].astype(\u001b[38;5;28mstr\u001b[39m).map(standardize_emd_name)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mADM_CODE_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m g.columns) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m g.columns):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(g.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    115\u001b[39m g[\u001b[33m\"\u001b[39m\u001b[33marea_km2\u001b[39m\u001b[33m\"\u001b[39m] = g.geometry.area / \u001b[32m1_000_000.0\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "\u001b[31mRuntimeError\u001b[39m: 읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼=['geometry']"
     ]
    }
   ],
   "source": [
    "#catboost\n",
    "\n",
    "from pathlib import Path\n",
    "import os, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===== install check =====\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "except ImportError:\n",
    "    raise SystemExit(\n",
    "        \"CatBoost가 설치되어 있지 않습니다. 터미널에서:\\n\"\n",
    "        \"  pip install catboost\\n\"\n",
    "        \"설치 후 다시 실행하세요.\"\n",
    "    )\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 경로/옵션\n",
    "# -------------------------------------------------\n",
    "BASE = Path(r\"C:\\공모전\\2025천안\")\n",
    "OUT  = BASE / \"outputs\" / \"CatBoost\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SHP_PATH = BASE / \"천안시경계(24).shp\"   # 또는 .gpkg (아래 read_shp_with_restore가 .shx 복구 시도)\n",
    "POP_DIR  = BASE / \"주민등록인구\"          # 보유한 읍면동 인구 파일(월/연/스냅샷) 폴더\n",
    "SCHOOL_CSV   = BASE / \"초중등학교 데이터\" / \"전국초중등학교위치표준데이터.csv\"\n",
    "BUS_CSV      = BASE / \"버스정류장 위치정보\" / \"국토교통부_전국 버스정류장 위치정보.csv\"\n",
    "HOSPITAL_CSV = BASE / \"병원정보서비스\" / \"병원정보서비스.csv\"\n",
    "\n",
    "YEARS = [2020, 2021, 2022, 2023, 2024]\n",
    "DEFAULT_PROJ = \"EPSG:5179\"  # Korea 2000 / Unified CS\n",
    "\n",
    "# 타깃 후보(우선순위)\n",
    "TARGET_CANDIDATES = [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"총인구\",\"population\",\"total_pop\"]\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 유틸(컬럼 추정/정규화)\n",
    "# -------------------------------------------------\n",
    "os.environ[\"SHAPE_RESTORE_SHX\"] = \"YES\"  # .shx 누락 자동복구 허용\n",
    "\n",
    "EMD_NAME_CANDS = [\n",
    "    \"EMD_NM\",\"EMD_KOR_NM\",\"EMD_NAME\",\"EMD_NM_KR\",\"EMD_NM_KOR\",\"EMD_NM_KO\",\n",
    "    \"읍면동\",\"읍면동명\",\"행정동\",\"행정동명\",\"법정동\",\"법정동명\",\"adm_nm\",\"adm_dr_nm\",\"NAME\",\"name\",\"동리명\"\n",
    "]\n",
    "EMD_CODE_CANDS = [\n",
    "    \"EMD_CD\",\"EMDCD\",\"ADM_CD\",\"adm_cd\",\"법정동코드\",\"행정동코드\",\"법정리코드\",\"법정동코드(10자리)\",\"HCODE\",\"CODE\"\n",
    "]\n",
    "POP_NAME_CANDS = [\"읍면동\",\"읍면동명\",\"행정동\",\"행정동명\",\"법정동\",\"법정동명\",\"adm_nm\",\"EMD_NM\",\"동리명\",\"NAME\",\"name\"]\n",
    "POP_CODE_CANDS = [\"행정동코드\",\"법정동코드\",\"EMD_CD\",\"adm_cd\",\"CODE\",\"HCODE\"]\n",
    "\n",
    "def pick_col(cols, cands):\n",
    "    # 정확 일치\n",
    "    for c in cands:\n",
    "        if c in cols: return c\n",
    "    # 공백/대소문자 무시\n",
    "    norm = {re.sub(r\"\\s+\",\"\",c).lower(): c for c in cols}\n",
    "    for cand in cands:\n",
    "        key = re.sub(r\"\\s+\",\"\",cand).lower()\n",
    "        if key in norm: return norm[key]\n",
    "    # 부분 포함\n",
    "    for c in cols:\n",
    "        for cand in cands:\n",
    "            if re.sub(r\"\\s+\",\"\",cand).lower() in re.sub(r\"\\s+\",\"\",c).lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def standardize_emd_name(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def normalize_adm_code(series, zfill=10):\n",
    "    return series.astype(str).str.replace(r\"\\D\", \"\", regex=True).str.zfill(zfill)\n",
    "\n",
    "def guess_emd_name_col(gdf: gpd.GeoDataFrame):\n",
    "    cand = []\n",
    "    for c in gdf.columns:\n",
    "        if gdf[c].dtype == \"object\":\n",
    "            s = gdf[c].astype(str).head(200)\n",
    "            ratio = s.str.contains(r\"(동|읍|면|리)$\").mean()\n",
    "            if ratio >= 0.2: cand.append((ratio, c))\n",
    "    if cand:\n",
    "        cand.sort(reverse=True)\n",
    "        return cand[0][1]\n",
    "    return None\n",
    "\n",
    "def read_shp_with_restore(shp_path: str, default_crs=DEFAULT_PROJ):\n",
    "    import fiona\n",
    "    with fiona.Env(SHAPE_RESTORE_SHX=\"YES\"):\n",
    "        g = gpd.read_file(shp_path)\n",
    "    if g.crs is None:\n",
    "        g = g.set_crs(default_crs, allow_override=True)\n",
    "    return g\n",
    "\n",
    "def resolve_emd_keys_from_shp(shp_path: str) -> gpd.GeoDataFrame:\n",
    "    g = read_shp_with_restore(shp_path)\n",
    "    code_col = pick_col(g.columns, EMD_CODE_CANDS)\n",
    "    name_col = pick_col(g.columns, EMD_NAME_CANDS) or guess_emd_name_col(g)\n",
    "    if code_col is not None:\n",
    "        g[\"ADM_CODE_STD\"] = normalize_adm_code(g[code_col])\n",
    "    if name_col is not None:\n",
    "        g[\"EMD_NAME_STD\"] = g[name_col].astype(str).map(standardize_emd_name)\n",
    "    if (\"ADM_CODE_STD\" not in g.columns) and (\"EMD_NAME_STD\" not in g.columns):\n",
    "        raise RuntimeError(f\"읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼={list(g.columns)}\")\n",
    "    g[\"area_km2\"] = g.geometry.area / 1_000_000.0\n",
    "    return g\n",
    "\n",
    "def detect_latlon(df: pd.DataFrame):\n",
    "    lat_cands = [\"위도\",\"lat\",\"latitude\",\"Y\",\"y\",\"WGS84위도\",\"Y좌표\",\"Y좌표(WGS84)\"]\n",
    "    lon_cands = [\"경도\",\"lon\",\"longitude\",\"X\",\"x\",\"WGS84경도\",\"X좌표\",\"X좌표(WGS84)\"]\n",
    "    lat = pick_col(df.columns, lat_cands)\n",
    "    lon = pick_col(df.columns, lon_cands)\n",
    "    return lat, lon\n",
    "\n",
    "def to_points(df: pd.DataFrame, lat: str, lon: str, crs=\"EPSG:4326\") -> gpd.GeoDataFrame:\n",
    "    d = df.dropna(subset=[lat, lon]).copy()\n",
    "    d[lat] = pd.to_numeric(d[lat], errors=\"coerce\")\n",
    "    d[lon] = pd.to_numeric(d[lon], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[lat, lon])\n",
    "    return gpd.GeoDataFrame(d, geometry=gpd.points_from_xy(d[lon], d[lat]), crs=crs)\n",
    "\n",
    "def project_like(g: gpd.GeoDataFrame, like: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    if g.crs is None: g = g.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "    if like.crs is None: like = like.set_crs(DEFAULT_PROJ, allow_override=True)\n",
    "    if g.crs != like.crs: g = g.to_crs(like.crs)\n",
    "    return g\n",
    "\n",
    "def sjoin_counts_and_nearest(points_gdf, emd, prefix):\n",
    "    emd_cent = emd.copy(); emd_cent[\"centroid\"] = emd.geometry.centroid\n",
    "    emd_cent = emd_cent.set_geometry(\"centroid\")\n",
    "    # 최근접 거리\n",
    "    if len(points_gdf) > 0:\n",
    "        nn = gpd.sjoin_nearest(emd_cent, points_gdf[[\"geometry\"]], how=\"left\", distance_col=f\"{prefix}_nearest_m\")\n",
    "        near = nn[[f\"{prefix}_nearest_m\"]].reindex(emd.index)\n",
    "    else:\n",
    "        near = pd.DataFrame({f\"{prefix}_nearest_m\":[np.nan]*len(emd)}, index=emd.index)\n",
    "    # 포함 카운트\n",
    "    if len(points_gdf) > 0:\n",
    "        jj = gpd.sjoin(emd, points_gdf[[\"geometry\"]], how=\"left\", predicate=\"contains\")\n",
    "        counts = jj.groupby(jj.index).size().reindex(emd.index).fillna(0).astype(int)\n",
    "    else:\n",
    "        counts = pd.Series(0, index=emd.index, dtype=int)\n",
    "    out = pd.DataFrame(index=emd.index)\n",
    "    out[f\"{prefix}_count\"] = counts\n",
    "    area = (emd.geometry.area/1_000_000.0).replace(0, np.nan)\n",
    "    out[f\"{prefix}_dens_km2\"] = out[f\"{prefix}_count\"] / area\n",
    "    out[f\"{prefix}_dens_log1p\"] = np.log1p(out[f\"{prefix}_dens_km2\"])\n",
    "    out = pd.concat([out, near], axis=1)\n",
    "    out[f\"{prefix}_nearest_km\"] = out[f\"{prefix}_nearest_m\"] / 1000.0\n",
    "    out[f\"{prefix}_nearest_log1p\"] = np.log1p(out[f\"{prefix}_nearest_km\"])\n",
    "    return out\n",
    "\n",
    "def zscore(s: pd.Series):\n",
    "    return (s - s.mean()) / (s.std(ddof=0) + 1e-9)\n",
    "\n",
    "def read_any_table(p: Path) -> pd.DataFrame:\n",
    "    if p.suffix.lower() == \".csv\":\n",
    "        for enc in (\"utf-8-sig\",\"cp949\",\"euc-kr\"):\n",
    "            try: return pd.read_csv(p, encoding=enc)\n",
    "            except UnicodeDecodeError: continue\n",
    "        return pd.read_csv(p)\n",
    "    else:\n",
    "        return pd.read_excel(p)\n",
    "\n",
    "def find_pop_files(pop_dir: Path):\n",
    "    pats=[r\".*인구.*\\.(csv|xlsx)$\", r\".*주민.*\\.(csv|xlsx)$\", r\".*세대.*\\.(csv|xlsx)$\"]\n",
    "    files=[]\n",
    "    for fp in pop_dir.glob(\"**/*\"):\n",
    "        if fp.is_file() and any(re.match(p, fp.name, flags=re.I) for p in pats):\n",
    "            files.append(fp)\n",
    "    return files\n",
    "\n",
    "def coerce_ym(s):\n",
    "    if pd.isna(s): return (None,None)\n",
    "    t=str(s).strip().replace(\".\",\"\").replace(\"-\",\"\").replace(\"/\",\"\")\n",
    "    if len(t)>=6 and t[:6].isdigit(): return (int(t[:4]), int(t[4:6]))\n",
    "    if len(t)==4 and t.isdigit(): return (int(t),12)\n",
    "    return (None,None)\n",
    "\n",
    "def resolve_keys_from_pop(df_in: pd.DataFrame):\n",
    "    df = df_in.copy()\n",
    "    code_col = pick_col(df.columns, POP_CODE_CANDS)\n",
    "    name_col = pick_col(df.columns, POP_NAME_CANDS)\n",
    "    if code_col is not None:\n",
    "        df[\"ADM_CODE_STD\"] = normalize_adm_code(df[code_col])\n",
    "    if name_col is not None:\n",
    "        df[\"EMD_NAME_STD\"] = df[name_col].astype(str).map(standardize_emd_name)\n",
    "    if (\"ADM_CODE_STD\" not in df.columns) and (\"EMD_NAME_STD\" not in df.columns):\n",
    "        # 값 패턴으로 이름 추정\n",
    "        for c in df.columns:\n",
    "            if df[c].dtype == \"object\":\n",
    "                s = df[c].astype(str).head(200)\n",
    "                if s.str.contains(r\"(동|읍|면|리)$\").mean() >= 0.2:\n",
    "                    df[\"EMD_NAME_STD\"] = df[c].astype(str).map(standardize_emd_name)\n",
    "                    break\n",
    "    return df\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 데이터 로드 & 피처 생성\n",
    "# -------------------------------------------------\n",
    "print(\"[INFO] EMD 경계 읽기\")\n",
    "emd = resolve_emd_keys_from_shp(str(SHP_PATH))\n",
    "BOUNDARY_HAS_CODE = \"ADM_CODE_STD\" in emd.columns\n",
    "BOUNDARY_HAS_NAME = \"EMD_NAME_STD\" in emd.columns\n",
    "idx_col = \"EMD_NAME_STD\" if BOUNDARY_HAS_NAME else \"ADM_CODE_STD\"\n",
    "emd = emd.set_index(idx_col, drop=False)\n",
    "\n",
    "print(\"[INFO] POI 읽기\")\n",
    "def read_poi(csv_path: Path, emd):\n",
    "    if not csv_path.exists():\n",
    "        print(f\"[WARN] POI 파일 없음: {csv_path.name}\")\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    try: df = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "    except UnicodeDecodeError: df = pd.read_csv(csv_path, encoding=\"cp949\")\n",
    "    lat,lon = detect_latlon(df)\n",
    "    if not (lat and lon):\n",
    "        print(f\"[WARN] 위경도 컬럼 자동탐색 실패 → 빈 처리: {csv_path.name}\")\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    g = to_points(df, lat, lon, crs=\"EPSG:4326\")\n",
    "    return project_like(g, emd)\n",
    "\n",
    "g_school = read_poi(SCHOOL_CSV, emd)\n",
    "g_bus    = read_poi(BUS_CSV, emd)\n",
    "g_hosp   = read_poi(HOSPITAL_CSV, emd)\n",
    "\n",
    "print(\"[INFO] 정적 피처 생성\")\n",
    "f_school = sjoin_counts_and_nearest(g_school, emd, \"school\")\n",
    "f_bus    = sjoin_counts_and_nearest(g_bus, emd, \"bus\")\n",
    "f_hosp   = sjoin_counts_and_nearest(g_hosp, emd, \"hosp\")\n",
    "feat_static = pd.concat([f_school, f_bus, f_hosp], axis=1)\n",
    "feat_static[\"school_z\"] = zscore(feat_static[\"school_dens_km2\"].fillna(0))\n",
    "feat_static[\"bus_z\"]    = zscore(feat_static[\"bus_dens_km2\"].fillna(0))\n",
    "feat_static[\"hosp_z\"]   = zscore(feat_static[\"hosp_dens_km2\"].fillna(0))\n",
    "# 합성 가중치 (도메인 priors)\n",
    "feat_static[\"YouthIndex\"]      = 0.5*feat_static[\"school_z\"] + 0.3*feat_static[\"bus_z\"] + 0.2*feat_static[\"hosp_z\"]\n",
    "feat_static[\"SeniorCareIndex\"] = 0.6*feat_static[\"hosp_z\"]  + 0.3*feat_static[\"bus_z\"] + 0.1*feat_static[\"school_z\"]\n",
    "feat_static[\"area_km2\"] = emd[\"area_km2\"]\n",
    "\n",
    "print(\"[INFO] 인구 표 읽기/연도화\")\n",
    "def build_population(pop_dir: Path, years: list):\n",
    "    files = find_pop_files(pop_dir)\n",
    "    if not files:\n",
    "        print(f\"[WARN] 인구 파일이 없습니다: {pop_dir}\")\n",
    "        return pd.DataFrame()\n",
    "    frames=[]\n",
    "    for p in files:\n",
    "        df = read_any_table(p)\n",
    "        df = resolve_keys_from_pop(df)\n",
    "        # 연/월 추출\n",
    "        ym_col = pick_col(df.columns, [\"기준년월\",\"년월\",\"연월\",\"yyyymm\",\"기준일자\",\"date\",\"집계년월\"])\n",
    "        year_col = pick_col(df.columns, [\"연도\",\"년도\",\"year\",\"Year\"])\n",
    "        month_col= pick_col(df.columns, [\"월\",\"month\",\"Month\"])\n",
    "        if ym_col:\n",
    "            ym=df[ym_col].map(coerce_ym); df[\"__year__\"]=[y for y,_ in ym]; df[\"__month__\"]=[m for _,m in ym]\n",
    "        elif year_col:\n",
    "            df[\"__year__\"]=pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "            df[\"__month__\"]=pd.to_numeric(df[month_col], errors=\"coerce\") if month_col else 12\n",
    "        else:\n",
    "            m=re.search(r\"(20\\d{2})(0[1-9]|1[0-2])\", p.stem)\n",
    "            if m: df[\"__year__\"]=int(m.group(1)); df[\"__month__\"]=int(m.group(2))\n",
    "            else:\n",
    "                m2=re.search(r\"(20\\d{2})\", p.stem)\n",
    "                df[\"__year__\"]=int(m2.group(1)) if m2 else np.nan; df[\"__month__\"]=12\n",
    "\n",
    "        # 타깃 후보 준비\n",
    "        total = pick_col(df.columns, [\"총인구\",\"인구\",\"총인구수\",\"population\",\"total_pop\"])\n",
    "        aged  = pick_col(df.columns, [\"65세이상\",\"65세이상인구\",\"고령인구\",\"over65\"])\n",
    "        aging = pick_col(df.columns, [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"ratio_65\"])\n",
    "        keep = [\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\",\"__month__\"] + [c for c in [total, aged, aging] if c]\n",
    "        df2 = df[keep].copy()\n",
    "        frames.append(df2)\n",
    "\n",
    "    pop = pd.concat(frames, ignore_index=True)\n",
    "    pop = pop.dropna(subset=[\"__year__\"])\n",
    "    pop = pop[pop[\"__year__\"].isin(years)]\n",
    "    # 월 자료면 최신월(연말/가장 최근) 선택\n",
    "    pop = pop.sort_values([\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\",\"__month__\"])\n",
    "    pop = pop.groupby([\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\"], as_index=False).tail(1)\n",
    "\n",
    "    # 고령화율 계산(없으면)\n",
    "    if \"aging_rate\" not in pop.columns:\n",
    "        tcol = pick_col(pop.columns, [\"총인구\",\"인구\",\"총인구수\",\"population\",\"total_pop\"])\n",
    "        acol = pick_col(pop.columns, [\"65세이상\",\"65세이상인구\",\"고령인구\",\"over65\"])\n",
    "        if tcol and acol:\n",
    "            pop[\"aging_rate\"] = pd.to_numeric(pop[acol], errors=\"coerce\")/pd.to_numeric(pop[tcol], errors=\"coerce\")\n",
    "    pop = pop.rename(columns={\"__year__\":\"year\"})\n",
    "    return pop\n",
    "\n",
    "pop_yearly = build_population(POP_DIR, YEARS)\n",
    "if pop_yearly.empty:\n",
    "    raise SystemExit(\"[ERROR] 인구 데이터가 비었습니다. POP_DIR에 파일을 넣고 다시 실행하세요.\")\n",
    "\n",
    "# 연패널(정적 피처는 연도별 복제)\n",
    "panel = []\n",
    "for y in YEARS:\n",
    "    tmp = feat_static.copy()\n",
    "    tmp[\"year\"] = y\n",
    "    # 병합 키 컬럼 추가\n",
    "    if \"EMD_NAME_STD\" in emd.columns:\n",
    "        tmp[\"EMD_NAME_STD\"] = emd[\"EMD_NAME_STD\"]\n",
    "    if \"ADM_CODE_STD\" in emd.columns:\n",
    "        tmp[\"ADM_CODE_STD\"] = emd[\"ADM_CODE_STD\"]\n",
    "    panel.append(tmp.reset_index(drop=True))\n",
    "panel = pd.concat(panel, axis=0)\n",
    "\n",
    "# 병합 키 결정(코드 우선)\n",
    "POP_HAS_CODE = \"ADM_CODE_STD\" in pop_yearly.columns\n",
    "POP_HAS_NAME = \"EMD_NAME_STD\" in pop_yearly.columns\n",
    "BOUNDARY_HAS_CODE = \"ADM_CODE_STD\" in panel.columns\n",
    "BOUNDARY_HAS_NAME = \"EMD_NAME_STD\" in panel.columns\n",
    "\n",
    "if BOUNDARY_HAS_CODE and POP_HAS_CODE:\n",
    "    key = \"ADM_CODE_STD\"\n",
    "elif BOUNDARY_HAS_NAME and POP_HAS_NAME:\n",
    "    key = \"EMD_NAME_STD\"\n",
    "else:\n",
    "    # 둘 다 있지 않으면 이름 기준 시도\n",
    "    key = \"EMD_NAME_STD\" if POP_HAS_NAME else \"ADM_CODE_STD\"\n",
    "\n",
    "data = pop_yearly.merge(panel, on=[key,\"year\"], how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# 타깃 및 피처 준비  (여기가 X, y, groups 생성부!)\n",
    "# -----------------------------\n",
    "tgt = None\n",
    "for cand in TARGET_CANDIDATES:\n",
    "    if cand in data.columns:\n",
    "        tgt = cand; break\n",
    "if tgt is None:\n",
    "    raise SystemExit(\"[ERROR] 타깃 컬럼(고령화율/총인구 등)이 데이터에 없습니다.\")\n",
    "\n",
    "feature_cols = [\n",
    "    # 밀도/거리형\n",
    "    \"school_dens_km2\",\"bus_dens_km2\",\"hosp_dens_km2\",\n",
    "    \"school_dens_log1p\",\"bus_dens_log1p\",\"hosp_dens_log1p\",\n",
    "    \"school_nearest_km\",\"bus_nearest_km\",\"hosp_nearest_km\",\n",
    "    \"school_nearest_log1p\",\"bus_nearest_log1p\",\"hosp_nearest_log1p\",\n",
    "    # 합성지표\n",
    "    \"YouthIndex\",\"SeniorCareIndex\",\n",
    "    # 면적\n",
    "    \"area_km2\",\n",
    "]\n",
    "feature_cols = [c for c in feature_cols if c in data.columns]\n",
    "for c in feature_cols:\n",
    "    data[c] = pd.to_numeric(data[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "y = pd.to_numeric(data[tgt], errors=\"coerce\")\n",
    "mask = ~y.isna()\n",
    "data = data.loc[mask].reset_index(drop=True)\n",
    "y = y.loc[mask].reset_index(drop=True)\n",
    "X = data[feature_cols].copy()        # ←← 바로 이 줄이 없으면 'X is not defined'가 납니다!\n",
    "groups = data[\"year\"].astype(int)\n",
    "\n",
    "print(f\"[INFO] Target={tgt}, X shape={X.shape}, years={sorted(groups.unique())}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 학습/검증\n",
    "# -------------------------------------------------\n",
    "def run_cv_catboost(X, y, groups):\n",
    "    gkf = GroupKFold(n_splits=len(YEARS))\n",
    "    oof = np.full(len(y), np.nan)\n",
    "    rows = []\n",
    "\n",
    "    for fold, (tr, va) in enumerate(gkf.split(X, y, groups=groups), 1):\n",
    "        model = CatBoostRegressor(\n",
    "            iterations=2200,\n",
    "            learning_rate=0.03,\n",
    "            depth=8,\n",
    "            loss_function=\"RMSE\",\n",
    "            random_state=42,\n",
    "            verbose=False\n",
    "        )\n",
    "        model.fit(X.iloc[tr], y.iloc[tr], verbose=False)\n",
    "        pred = model.predict(X.iloc[va])\n",
    "        oof[va] = pred\n",
    "\n",
    "        r2   = r2_score(y.iloc[va], pred)\n",
    "        mae  = mean_absolute_error(y.iloc[va], pred)\n",
    "        rmse = mean_squared_error(y.iloc[va], pred, squared=False)\n",
    "        yr   = int(groups.iloc[va].iloc[0])\n",
    "        rows.append({\"fold\":fold,\"valid_year\":yr,\"R2\":r2,\"MAE\":mae,\"RMSE\":rmse})\n",
    "        print(f\"[CatBoost] Fold{fold} (valid {yr}) R2={r2:.3f} MAE={mae:.3f} RMSE={rmse:.3f}\")\n",
    "\n",
    "    cv_df = pd.DataFrame(rows)\n",
    "    cv_df.to_csv(OUT/\"cv_CatBoost.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 중요도 저장 (Permutation + 내장 중요도)\n",
    "    try:\n",
    "        # 마지막 학습 모델로 대체 측정 (간단화)\n",
    "        model_final = CatBoostRegressor(\n",
    "            iterations=2200, learning_rate=0.03, depth=8, loss_function=\"RMSE\",\n",
    "            random_state=42, verbose=False\n",
    "        )\n",
    "        model_final.fit(X, y, verbose=False)\n",
    "        imp_perm = permutation_importance(model_final, X, y, n_repeats=10, random_state=42)\n",
    "        pd.DataFrame({\n",
    "            \"feature\": X.columns,\n",
    "            \"perm_importance_mean\": imp_perm.importances_mean,\n",
    "            \"perm_importance_std\": imp_perm.importances_std\n",
    "        }).sort_values(\"perm_importance_mean\", ascending=False)\\\n",
    "          .to_csv(OUT/\"feat_importance_perm_CatBoost.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "        imp_cb = pd.Series(model_final.get_feature_importance(), index=X.columns).sort_values(ascending=False)\n",
    "        imp_cb.reset_index().rename(columns={\"index\":\"feature\",0:\"catboost_importance\"})\\\n",
    "              .to_csv(OUT/\"feat_importance_cb_CatBoost.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "        # 최종 모델 저장\n",
    "        joblib.dump(model_final, OUT/\"final_catboost.pkl\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] 중요도/최종모델 저장 중 오류:\", e)\n",
    "\n",
    "    # OOF 저장\n",
    "    oof_df = data[[\"EMD_NAME_STD\",\"ADM_CODE_STD\",\"year\"]].copy()\n",
    "    oof_df[\"y_true\"] = y.values\n",
    "    oof_df[\"y_pred\"] = oof\n",
    "    oof_df.to_csv(OUT/\"oof_CatBoost.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # 입력 패널 저장(재현성)\n",
    "    data_out = data[[\"EMD_NAME_STD\",\"ADM_CODE_STD\",\"year\",tgt] + feature_cols].copy()\n",
    "    data_out.to_csv(OUT/\"model_input_panel.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "run_cv_catboost(X, y, groups)\n",
    "print(\"[DONE] 결과 저장 폴더:\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "425cc101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Load EMD boundary\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'EMD_KOR_NM'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\공모전\\2025천안\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'EMD_KOR_NM'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 179\u001b[39m\n\u001b[32m    177\u001b[39m emd = read_shp(SHP_PATH)\n\u001b[32m    178\u001b[39m emd_name = pick_col(emd.columns, EMD_NAME_CANDS) \u001b[38;5;129;01mor\u001b[39;00m EMD_NAME_CANDS[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m emd[\u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[43memd\u001b[49m\u001b[43m[\u001b[49m\u001b[43memd_name\u001b[49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m).map(standardize_emd_name)\n\u001b[32m    180\u001b[39m emd = emd.set_index(\u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m, drop=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    181\u001b[39m emd[\u001b[33m\"\u001b[39m\u001b[33marea_km2\u001b[39m\u001b[33m\"\u001b[39m]=(emd.geometry.area/\u001b[32m1_000_000.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\공모전\\2025천안\\.venv\\Lib\\site-packages\\geopandas\\geodataframe.py:1459\u001b[39m, in \u001b[36mGeoDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1453\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   1454\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1455\u001b[39m \u001b[33;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[32m   1456\u001b[39m \u001b[33;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[32m   1457\u001b[39m \u001b[33;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[32m   1458\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1459\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1460\u001b[39m     \u001b[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001b[39;00m\n\u001b[32m   1461\u001b[39m     \u001b[38;5;66;03m# result is not geometry dtype for multi-indexes\u001b[39;00m\n\u001b[32m   1462\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1463\u001b[39m         pd.api.types.is_scalar(key)\n\u001b[32m   1464\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1467\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_geometry_type(result)\n\u001b[32m   1468\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\공모전\\2025천안\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\공모전\\2025천안\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'EMD_KOR_NM'"
     ]
    }
   ],
   "source": [
    "#RandomBoost\n",
    "from pathlib import Path\n",
    "import warnings, re, math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "\n",
    "# ========= 경로/옵션 =========\n",
    "BASE = Path(r\"C:\\공모전\\2025천안\")\n",
    "OUT  = BASE / \"outputs\" / \"RandomForest\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SHP_PATH = BASE / \"천안시경계(24).shp\"\n",
    "POP_DIR  = BASE / \"주민등록인구\"  # 사용자 보유 데이터 폴더\n",
    "SCHOOL_CSV   = BASE / \"초중등학교 데이터\" / \"전국초중등학교위치표준데이터.csv\"\n",
    "BUS_CSV      = BASE / \"버스정류장 위치정보\" / \"국토교통부_전국 버스정류장 위치정보.csv\"\n",
    "HOSPITAL_CSV = BASE / \"병원정보서비스\" / \"병원정보서비스.csv\"\n",
    "FRESHMAN_DIR = BASE / \"충원률\"\n",
    "YEARS = [2020, 2021, 2022, 2023, 2024]\n",
    "DEFAULT_PROJ = \"EPSG:5179\"\n",
    "\n",
    "TARGET_CANDIDATES = [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"총인구\",\"population\",\"total_pop\"]\n",
    "EMD_NAME_CANDS = [\"EMD_KOR_NM\",\"EMD_NM\",\"읍면동\",\"EMD\",\"adm_nm\",\"EMD_NM_KR\"]\n",
    "\n",
    "# ========= 공통 유틸 =========\n",
    "def pick_col(cols, cands):\n",
    "    for c in cands:\n",
    "        if c in cols: return c\n",
    "    norm = {re.sub(r\"\\s+\",\"\",c).lower(): c for c in cols}\n",
    "    for cand in cands:\n",
    "        key = re.sub(r\"\\s+\",\"\",cand).lower()\n",
    "        if key in norm: return norm[key]\n",
    "    for c in cols:\n",
    "        for cand in cands:\n",
    "            if re.sub(r\"\\s+\",\"\",cand).lower() in re.sub(r\"\\s+\",\"\",c).lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def read_shp(path: Path) -> gpd.GeoDataFrame:\n",
    "    g = gpd.read_file(path)\n",
    "    if g.crs is None: g = g.set_crs(DEFAULT_PROJ, allow_override=True)\n",
    "    return g\n",
    "\n",
    "def detect_latlon(df):\n",
    "    lat_cands = [\"위도\",\"lat\",\"latitude\",\"Y\",\"y\",\"WGS84위도\",\"Y좌표\",\"Y좌표(WGS84)\"]\n",
    "    lon_cands = [\"경도\",\"lon\",\"longitude\",\"X\",\"x\",\"WGS84경도\",\"X좌표\",\"X좌표(WGS84)\"]\n",
    "    lat = pick_col(df.columns, lat_cands); lon = pick_col(df.columns, lon_cands)\n",
    "    return lat, lon\n",
    "\n",
    "def to_points(df, lat, lon, crs=\"EPSG:4326\"):\n",
    "    d = df.dropna(subset=[lat,lon]).copy()\n",
    "    d[lat]=pd.to_numeric(d[lat], errors=\"coerce\"); d[lon]=pd.to_numeric(d[lon], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[lat,lon])\n",
    "    return gpd.GeoDataFrame(d, geometry=gpd.points_from_xy(d[lon], d[lat]), crs=crs)\n",
    "\n",
    "def project_like(g, like):\n",
    "    if g.crs is None: g = g.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "    if like.crs is None: like = like.set_crs(DEFAULT_PROJ, allow_override=True)\n",
    "    if g.crs != like.crs: g = g.to_crs(like.crs)\n",
    "    return g\n",
    "\n",
    "def zscore(s): return (s - s.mean()) / (s.std(ddof=0) + 1e-9)\n",
    "\n",
    "def standardize_emd_name(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    return re.sub(r\"\\s+\",\"\",str(s).strip())\n",
    "\n",
    "def sjoin_counts_and_nearest(points_gdf, emd, prefix):\n",
    "    emd_cent = emd.copy(); emd_cent[\"centroid\"] = emd.geometry.centroid\n",
    "    emd_cent = emd_cent.set_geometry(\"centroid\")\n",
    "    # 최근접 거리\n",
    "    if len(points_gdf)>0:\n",
    "        nn = gpd.sjoin_nearest(emd_cent, points_gdf[[\"geometry\"]], how=\"left\", distance_col=f\"{prefix}_nearest_m\")\n",
    "        near = nn[[f\"{prefix}_nearest_m\"]].reindex(emd.index)\n",
    "    else:\n",
    "        near = pd.DataFrame({f\"{prefix}_nearest_m\":[np.nan]*len(emd)}, index=emd.index)\n",
    "    # 포함 카운트\n",
    "    if len(points_gdf)>0:\n",
    "        jj = gpd.sjoin(emd, points_gdf[[\"geometry\"]], how=\"left\", predicate=\"contains\")\n",
    "        counts = jj.groupby(jj.index).size().reindex(emd.index).fillna(0).astype(int)\n",
    "    else:\n",
    "        counts = pd.Series(0, index=emd.index, dtype=int)\n",
    "    out = pd.DataFrame(index=emd.index)\n",
    "    out[f\"{prefix}_count\"]=counts\n",
    "    area = (emd.geometry.area/1_000_000.0).replace(0,np.nan)\n",
    "    out[f\"{prefix}_dens_km2\"] = out[f\"{prefix}_count\"]/area\n",
    "    out[f\"{prefix}_dens_log1p\"]=np.log1p(out[f\"{prefix}_dens_km2\"])\n",
    "    out = pd.concat([out, near], axis=1)\n",
    "    out[f\"{prefix}_nearest_km\"]=out[f\"{prefix}_nearest_m\"]/1000.0\n",
    "    out[f\"{prefix}_nearest_log1p\"]=np.log1p(out[f\"{prefix}_nearest_km\"])\n",
    "    return out\n",
    "\n",
    "def read_poi(csv_path, emd):\n",
    "    if not csv_path.exists():\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    try: df = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "    except UnicodeDecodeError: df = pd.read_csv(csv_path, encoding=\"cp949\")\n",
    "    lat,lon = detect_latlon(df)\n",
    "    if not (lat and lon): return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    g = to_points(df, lat, lon, crs=\"EPSG:4326\")\n",
    "    return project_like(g, emd)\n",
    "\n",
    "def coerce_ym(s):\n",
    "    if pd.isna(s): return (None,None)\n",
    "    t=str(s).strip().replace(\".\",\"\").replace(\"-\",\"\").replace(\"/\",\"\")\n",
    "    if len(t)>=6 and t[:6].isdigit(): return (int(t[:4]), int(t[4:6]))\n",
    "    if len(t)==4 and t.isdigit(): return (int(t),12)\n",
    "    return (None,None)\n",
    "\n",
    "def read_any_table(p: Path):\n",
    "    if p.suffix.lower()==\".csv\":\n",
    "        for enc in (\"utf-8-sig\",\"cp949\",\"euc-kr\"):\n",
    "            try: return pd.read_csv(p, encoding=enc)\n",
    "            except UnicodeDecodeError: continue\n",
    "        return pd.read_csv(p)\n",
    "    else:\n",
    "        return pd.read_excel(p)\n",
    "\n",
    "def find_pop_files(pop_dir: Path):\n",
    "    pats=[r\".*인구.*\\.(csv|xlsx)$\", r\".*주민.*\\.(csv|xlsx)$\", r\".*세대.*\\.(csv|xlsx)$\"]\n",
    "    files=[]\n",
    "    for fp in pop_dir.glob(\"**/*\"):\n",
    "        if fp.is_file() and any(re.match(p, fp.name, flags=re.I) for p in pats): files.append(fp)\n",
    "    return files\n",
    "\n",
    "def build_population(pop_dir, years, emd):\n",
    "    files=find_pop_files(pop_dir); frames=[]\n",
    "    for p in files:\n",
    "        df=read_any_table(p)\n",
    "        emd_col = pick_col(df.columns, [\"읍면동\",\"행정동\",\"법정동\",\"adm_nm\",\"EMD\",\"EMD_NM\",\"동리명\",\"법정동명\"])\n",
    "        if not emd_col: continue\n",
    "        ym_col = pick_col(df.columns, [\"기준년월\",\"년월\",\"연월\",\"yyyymm\",\"기준일자\",\"date\",\"집계년월\"])\n",
    "        year_col = pick_col(df.columns, [\"연도\",\"년도\",\"year\"])\n",
    "        month_col= pick_col(df.columns, [\"월\",\"month\"])\n",
    "        if ym_col:\n",
    "            ym=df[ym_col].map(coerce_ym); df[\"__year__\"]=[y for y,_ in ym]; df[\"__month__\"]=[m for _,m in ym]\n",
    "        elif year_col:\n",
    "            df[\"__year__\"]=pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "            df[\"__month__\"]=pd.to_numeric(df[month_col], errors=\"coerce\") if month_col else 12\n",
    "        else:\n",
    "            m=re.search(r\"(20\\d{2})(0[1-9]|1[0-2])\", p.stem)\n",
    "            if m: df[\"__year__\"]=int(m.group(1)); df[\"__month__\"]=int(m.group(2))\n",
    "            else:\n",
    "                m2=re.search(r\"(20\\d{2})\", p.stem)\n",
    "                df[\"__year__\"]=int(m2.group(1)) if m2 else np.nan; df[\"__month__\"]=12\n",
    "        total = pick_col(df.columns, [\"총인구\",\"인구\",\"총인구수\",\"population\",\"total_pop\"])\n",
    "        aged  = pick_col(df.columns, [\"65세이상\",\"65세이상인구\",\"고령인구\",\"over65\"])\n",
    "        aging = pick_col(df.columns, [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"ratio_65\"])\n",
    "        keep=[c for c in [emd_col,\"__year__\",\"__month__\",total,aged,aging] if c]\n",
    "        part=df[keep].copy()\n",
    "        part[\"EMD_NAME_STD\"]=part[emd_col].astype(str).map(standardize_emd_name)\n",
    "        frames.append(part)\n",
    "    if not frames: return pd.DataFrame()\n",
    "    pop=pd.concat(frames, ignore_index=True)\n",
    "    pop=pop.dropna(subset=[\"__year__\"]).query(\"__year__ in @YEARS\")\n",
    "    # 월별이 있으면 최신월, 아니면 단일행\n",
    "    pop=pop.sort_values([\"EMD_NAME_STD\",\"__year__\",\"__month__\"]).groupby([\"EMD_NAME_STD\",\"__year__\"]).tail(1)\n",
    "    # 고령화율 계산\n",
    "    if pick_col(pop.columns, [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"ratio_65\"]) is None:\n",
    "        tcol = pick_col(pop.columns, [\"총인구\",\"인구\",\"총인구수\",\"population\",\"total_pop\"])\n",
    "        acol = pick_col(pop.columns, [\"65세이상\",\"65세이상인구\",\"고령인구\",\"over65\"])\n",
    "        if tcol and acol:\n",
    "            pop[\"aging_rate\"]=pd.to_numeric(pop[acol], errors=\"coerce\")/pd.to_numeric(pop[tcol], errors=\"coerce\")\n",
    "    return pop\n",
    "\n",
    "# ========= 데이터 준비 =========\n",
    "print(\"[INFO] Load EMD boundary\")\n",
    "emd = read_shp(SHP_PATH)\n",
    "emd_name = pick_col(emd.columns, EMD_NAME_CANDS) or EMD_NAME_CANDS[0]\n",
    "emd[\"EMD_NAME_STD\"]=emd[emd_name].astype(str).map(standardize_emd_name)\n",
    "emd = emd.set_index(\"EMD_NAME_STD\", drop=False)\n",
    "emd[\"area_km2\"]=(emd.geometry.area/1_000_000.0)\n",
    "\n",
    "print(\"[INFO] Load POIs\")\n",
    "g_school = read_poi(SCHOOL_CSV, emd)\n",
    "g_bus    = read_poi(BUS_CSV, emd)\n",
    "g_hosp   = read_poi(HOSPITAL_CSV, emd)\n",
    "\n",
    "print(\"[INFO] Build static features\")\n",
    "f_school = sjoin_counts_and_nearest(g_school, emd, \"school\")\n",
    "f_bus    = sjoin_counts_and_nearest(g_bus, emd, \"bus\")\n",
    "f_hosp   = sjoin_counts_and_nearest(g_hosp, emd, \"hosp\")\n",
    "feat = pd.concat([f_school, f_bus, f_hosp], axis=1)\n",
    "feat[\"school_z\"]=zscore(feat[\"school_dens_km2\"].fillna(0))\n",
    "feat[\"bus_z\"]   =zscore(feat[\"bus_dens_km2\"].fillna(0))\n",
    "feat[\"hosp_z\"]  =zscore(feat[\"hosp_dens_km2\"].fillna(0))\n",
    "# 합성지표(가중치: Youth/SeniorCare)\n",
    "feat[\"YouthIndex\"]      = 0.5*feat[\"school_z\"] + 0.3*feat[\"bus_z\"] + 0.2*feat[\"hosp_z\"]\n",
    "feat[\"SeniorCareIndex\"] = 0.6*feat[\"hosp_z\"]  + 0.3*feat[\"bus_z\"] + 0.1*feat[\"school_z\"]\n",
    "feat[\"area_km2\"]=emd[\"area_km2\"]\n",
    "\n",
    "print(\"[INFO] Load population (annual)\")\n",
    "pop = build_population(POP_DIR, YEARS, emd)\n",
    "if pop.empty: raise SystemExit(\"[ERROR] 인구 데이터가 비어있습니다. POP_DIR 내용을 확인하세요.\")\n",
    "\n",
    "# 연패널 구성(정적 피처는 연도별 복제)\n",
    "panel=[]\n",
    "for y in YEARS:\n",
    "    tmp = feat.copy(); tmp[\"year\"]=y; tmp[\"EMD_NAME_STD\"]=tmp.index\n",
    "    panel.append(tmp.reset_index(drop=True))\n",
    "panel = pd.concat(panel, axis=0)\n",
    "\n",
    "data = pop.merge(panel, on=[\"EMD_NAME_STD\",\"year\"], how=\"left\")\n",
    "\n",
    "# 타깃 선택\n",
    "tgt=None\n",
    "for c in TARGET_CANDIDATES:\n",
    "    if c in data.columns: tgt=c; break\n",
    "if tgt is None:\n",
    "    raise SystemExit(\"[ERROR] 타깃 컬럼(고령화율/총인구 등)을 찾을 수 없습니다.\")\n",
    "\n",
    "feature_cols = [\n",
    "    \"school_dens_km2\",\"bus_dens_km2\",\"hosp_dens_km2\",\n",
    "    \"school_dens_log1p\",\"bus_dens_log1p\",\"hosp_dens_log1p\",\n",
    "    \"school_nearest_km\",\"bus_nearest_km\",\"hosp_nearest_km\",\n",
    "    \"school_nearest_log1p\",\"bus_nearest_log1p\",\"hosp_nearest_log1p\",\n",
    "    \"YouthIndex\",\"SeniorCareIndex\",\"area_km2\"\n",
    "]\n",
    "feature_cols=[c for c in feature_cols if c in data.columns]\n",
    "for c in feature_cols: data[c]=data[c].fillna(0)\n",
    "\n",
    "X=data[feature_cols].copy()\n",
    "y=pd.to_numeric(data[tgt], errors=\"coerce\")\n",
    "groups=data[\"year\"]\n",
    "\n",
    "# ========= 학습/평가 =========\n",
    "def run_cv(model_name, model, X, y, groups):\n",
    "    gkf=GroupKFold(n_splits=len(YEARS))\n",
    "    oof=np.full(len(y), np.nan)\n",
    "    rows=[]\n",
    "    for i,(tr,va) in enumerate(gkf.split(X,y,groups),1):\n",
    "        model.fit(X.iloc[tr], y.iloc[tr])\n",
    "        pred=model.predict(X.iloc[va])\n",
    "        oof[va]=pred\n",
    "        r2=r2_score(y.iloc[va],pred)\n",
    "        mae=mean_absolute_error(y.iloc[va],pred)\n",
    "        rmse=mean_squared_error(y.iloc[va],pred,squared=False)\n",
    "        yr=int(groups.iloc[va].iloc[0])\n",
    "        rows.append({\"fold\":i,\"valid_year\":yr,\"R2\":r2,\"MAE\":mae,\"RMSE\":rmse})\n",
    "        print(f\"[{model_name}] Fold{i} (valid {yr})  R2={r2:.3f}  MAE={mae:.3f}  RMSE={rmse:.3f}\")\n",
    "    pd.DataFrame(rows).to_csv(OUT/f\"cv_{model_name}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    # Permutation importance\n",
    "    try:\n",
    "        imp=permutation_importance(model, X, y, n_repeats=10, random_state=42)\n",
    "        pd.DataFrame({\"feature\":X.columns,\n",
    "                      \"perm_importance_mean\":imp.importances_mean,\n",
    "                      \"perm_importance_std\":imp.importances_std})\\\n",
    "          .sort_values(\"perm_importance_mean\", ascending=False)\\\n",
    "          .to_csv(OUT/f\"feat_importance_{model_name}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] permutation importance 실패:\", e)\n",
    "    out = data[[\"EMD_NAME_STD\",\"year\"]].copy()\n",
    "    out[\"y_true\"]=y.values; out[\"y_pred\"]=oof\n",
    "    out.to_csv(OUT/f\"oof_{model_name}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=700, max_depth=None, max_features=\"sqrt\",\n",
    "    min_samples_split=2, min_samples_leaf=1,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "run_cv(\"RandomForest\", rf, X, y, groups)\n",
    "\n",
    "# ========= 전체학습 & 저장 =========\n",
    "rf.fit(X,y)\n",
    "joblib.dump(rf, OUT/\"final_rf.pkl\")\n",
    "data_out = data[[\"EMD_NAME_STD\",\"year\",tgt]+feature_cols]\n",
    "data_out.to_csv(OUT/\"model_input_panel.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"[DONE] RandomForest outputs saved →\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fdaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 1) EMD 경계 읽기 & 키 생성\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼=['geometry']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 312\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;66;03m# ================== 데이터 로드/피처 구성 ==================\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[INFO] 1) EMD 경계 읽기 & 키 생성\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m emd = \u001b[43mresolve_emd_keys_from_shp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSHP_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m BOUNDARY_HAS_CODE = \u001b[33m\"\u001b[39m\u001b[33mADM_CODE_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m emd.columns\n\u001b[32m    314\u001b[39m BOUNDARY_HAS_NAME = \u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m emd.columns\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mresolve_emd_keys_from_shp\u001b[39m\u001b[34m(shp_path)\u001b[39m\n\u001b[32m    118\u001b[39m     g[\u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m] = g[name_col].astype(\u001b[38;5;28mstr\u001b[39m).map(standardize_emd_name)\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mADM_CODE_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m g.columns) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mEMD_NAME_STD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m g.columns):\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(g.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    121\u001b[39m g[\u001b[33m\"\u001b[39m\u001b[33marea_km2\u001b[39m\u001b[33m\"\u001b[39m] = g.geometry.area / \u001b[32m1_000_000.0\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "\u001b[31mRuntimeError\u001b[39m: 읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼=['geometry']"
     ]
    }
   ],
   "source": [
    "\n",
    "# LightGBM\n",
    "\n",
    "from pathlib import Path\n",
    "import warnings, re, os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd, numpy as np, geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from lightgbm import LGBMRegressor\n",
    "import joblib\n",
    "\n",
    "# ================== 경로/상수 ==================\n",
    "BASE = Path(r\"C:\\공모전\\2025천안\")\n",
    "OUT  = BASE / \"outputs\" / \"LightGBM_3_1_1\"; OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ▶ POP 입력(둘 중 택1): (A) 폴더 스캔 or (B) 단일 CSV 직접 지정\n",
    "# (A) 폴더 스캔 버전\n",
    "POP_DIR  = BASE / \"주민등록인구\"\n",
    "\n",
    "# (B) 단일 CSV 버전: 아래 두 줄 주석 해제하고 사용 (파일 경로 정확히!)\n",
    "# POP_FILE = BASE / \"시군구별 이동자\" / \"202001_202412_주민등록인구및세대현황_월간.csv\"\n",
    "# POP_INPUT_IS_FILE = True\n",
    "POP_INPUT_IS_FILE = False  # (A) 폴더 스캔 사용 시 False\n",
    "\n",
    "SHP_PATH = BASE / \"천안시경계(24).shp\"   # .shx 없어도 자동 복구 시도\n",
    "SCHOOL_CSV   = BASE / \"초중등학교 데이터\" / \"전국초중등학교위치표준데이터.csv\"\n",
    "BUS_CSV      = BASE / \"버스정류장 위치정보\" / \"국토교통부_전국 버스정류장 위치정보.csv\"\n",
    "HOSPITAL_CSV = BASE / \"병원정보서비스\" / \"병원정보서비스.csv\"\n",
    "\n",
    "# 기본 연도 세트 (필요 시 2025 추가 가능)\n",
    "YEARS = [2020, 2021, 2022, 2023, 2024]\n",
    "DEFAULT_PROJ = \"EPSG:5179\"  # Korea 2000 / Unified CS\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "TARGET_CANDIDATES = [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"총인구\",\"population\",\"total_pop\"]\n",
    "\n",
    "# shp 읽을 때 .shx 자동 복구 허용\n",
    "os.environ[\"SHAPE_RESTORE_SHX\"] = \"YES\"\n",
    "\n",
    "# 이름/코드 컬럼 후보(경계/인구 모두 대응)\n",
    "EMD_NAME_CANDS = [\n",
    "    \"EMD_NM\",\"EMD_KOR_NM\",\"EMD_NAME\",\"EMD_NM_KR\",\"EMD_NM_KOR\",\"EMD_NM_KO\",\n",
    "    \"읍면동\",\"읍면동명\",\"행정동\",\"행정동명\",\"법정동\",\"법정동명\",\"adm_nm\",\"adm_dr_nm\",\"NAME\",\"name\",\"동리명\"\n",
    "]\n",
    "EMD_CODE_CANDS = [\n",
    "    \"EMD_CD\",\"EMDCD\",\"ADM_CD\",\"adm_cd\",\"법정동코드\",\"행정동코드\",\"법정리코드\",\"법정동코드(10자리)\",\"HCODE\",\"CODE\"\n",
    "]\n",
    "POP_NAME_CANDS = [\"읍면동\",\"읍면동명\",\"행정동\",\"행정동명\",\"법정동\",\"법정동명\",\"adm_nm\",\"EMD_NM\",\"동리명\",\"NAME\",\"name\"]\n",
    "POP_CODE_CANDS = [\"행정동코드\",\"법정동코드\",\"EMD_CD\",\"adm_cd\",\"CODE\",\"HCODE\"]\n",
    "\n",
    "SIDO_CANDS = [\"시도\",\"시도명\",\"광역시도\",\"행정구역(시도)\"]\n",
    "SIG_CANDS  = [\"시군구\",\"시군구명\",\"자치구\",\"구\",\"군\",\"행정구역(시군구)\"]\n",
    "\n",
    "# ================== 유틸 함수 ==================\n",
    "def pick_col(cols, cands):\n",
    "    \"\"\"정확일치 → 공백/대소문자 무시 → 부분포함 순으로 첫 컬럼 반환\"\"\"\n",
    "    for c in cands:\n",
    "        if c in cols: return c\n",
    "    norm = {re.sub(r\"\\s+\",\"\",c).lower(): c for c in cols}\n",
    "    for cand in cands:\n",
    "        key = re.sub(r\"\\s+\",\"\",cand).lower()\n",
    "        if key in norm: return norm[key]\n",
    "    for c in cols:\n",
    "        for cand in cands:\n",
    "            if re.sub(r\"\\s+\",\"\",cand).lower() in re.sub(r\"\\s+\",\"\",c).lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def standardize_emd_name(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r\"\\s+\",\"\", s)\n",
    "    # 필요하면 접두부(천안시동남구/서북구) 제거 룰을 추가 가능\n",
    "    return s\n",
    "\n",
    "def normalize_adm_code(series, zfill=10):\n",
    "    \"\"\"숫자만 남겨 10자리(법정동코드 관용) zero-fill\"\"\"\n",
    "    return series.astype(str).str.replace(r\"\\D\",\"\", regex=True).str.zfill(zfill)\n",
    "\n",
    "def guess_emd_name_col(gdf: gpd.GeoDataFrame):\n",
    "    \"\"\"한글+동/읍/면/리로 끝나는 비율 높은 문자열 컬럼 자동 후보\"\"\"\n",
    "    cand=[]\n",
    "    for c in gdf.columns:\n",
    "        if gdf[c].dtype == \"object\":\n",
    "            s = gdf[c].astype(str).head(200)\n",
    "            ratio = s.str.contains(r\"(동|읍|면|리)$\").mean()\n",
    "            if ratio >= 0.2:\n",
    "                cand.append((ratio, c))\n",
    "    if cand:\n",
    "        cand.sort(reverse=True)\n",
    "        return cand[0][1]\n",
    "    return None\n",
    "\n",
    "def read_shp_with_restore(shp_path: str, default_crs=DEFAULT_PROJ):\n",
    "    import fiona\n",
    "    with fiona.Env(SHAPE_RESTORE_SHX=\"YES\"):\n",
    "        g = gpd.read_file(shp_path)\n",
    "    if g.crs is None:\n",
    "        g = g.set_crs(default_crs, allow_override=True)\n",
    "    return g\n",
    "\n",
    "def resolve_emd_keys_from_shp(shp_path: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"경계에서 이름/코드 표준 키 생성 + 면적 km² 추가\"\"\"\n",
    "    g = read_shp_with_restore(shp_path)\n",
    "    code_col = pick_col(g.columns, EMD_CODE_CANDS)\n",
    "    name_col = pick_col(g.columns, EMD_NAME_CANDS) or guess_emd_name_col(g)\n",
    "    if code_col is not None:\n",
    "        g[\"ADM_CODE_STD\"] = normalize_adm_code(g[code_col])\n",
    "    if name_col is not None:\n",
    "        g[\"EMD_NAME_STD\"] = g[name_col].astype(str).map(standardize_emd_name)\n",
    "    if (\"ADM_CODE_STD\" not in g.columns) and (\"EMD_NAME_STD\" not in g.columns):\n",
    "        raise RuntimeError(f\"읍면동 키(이름/코드)를 찾지 못했습니다. 컬럼={list(g.columns)}\")\n",
    "    g[\"area_km2\"] = g.geometry.area / 1_000_000.0\n",
    "    return g\n",
    "\n",
    "def detect_latlon(df: pd.DataFrame):\n",
    "    lat_cands = [\"위도\",\"lat\",\"latitude\",\"Y\",\"y\",\"WGS84위도\",\"Y좌표\",\"Y좌표(WGS84)\"]\n",
    "    lon_cands = [\"경도\",\"lon\",\"longitude\",\"X\",\"x\",\"WGS84경도\",\"X좌표\",\"X좌표(WGS84)\"]\n",
    "    lat = pick_col(df.columns, lat_cands)\n",
    "    lon = pick_col(df.columns, lon_cands)\n",
    "    return lat, lon\n",
    "\n",
    "def to_points(df: pd.DataFrame, lat: str, lon: str, crs=\"EPSG:4326\") -> gpd.GeoDataFrame:\n",
    "    d = df.dropna(subset=[lat, lon]).copy()\n",
    "    d[lat] = pd.to_numeric(d[lat], errors=\"coerce\")\n",
    "    d[lon] = pd.to_numeric(d[lon], errors=\"coerce\")\n",
    "    d = d.dropna(subset=[lat, lon])\n",
    "    return gpd.GeoDataFrame(d, geometry=gpd.points_from_xy(d[lon], d[lat]), crs=crs)\n",
    "\n",
    "def project_like(g: gpd.GeoDataFrame, like: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    if g.crs is None: g = g.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "    if like.crs is None: like = like.set_crs(DEFAULT_PROJ, allow_override=True)\n",
    "    if g.crs != like.crs: g = g.to_crs(like.crs)\n",
    "    return g\n",
    "\n",
    "def sjoin_counts_and_nearest(points_gdf, emd, prefix):\n",
    "    \"\"\"EMD 내 포함 카운트, km²당 밀도, 최근접거리(km) 및 로그보조\"\"\"\n",
    "    emd_cent = emd.copy(); emd_cent[\"centroid\"] = emd.geometry.centroid\n",
    "    emd_cent = emd_cent.set_geometry(\"centroid\")\n",
    "    # 최근접 거리\n",
    "    if len(points_gdf) > 0:\n",
    "        nn = gpd.sjoin_nearest(emd_cent, points_gdf[[\"geometry\"]], how=\"left\", distance_col=f\"{prefix}_nearest_m\")\n",
    "        near = nn[[f\"{prefix}_nearest_m\"]].reindex(emd.index)\n",
    "    else:\n",
    "        near = pd.DataFrame({f\"{prefix}_nearest_m\":[np.nan]*len(emd)}, index=emd.index)\n",
    "    # 포함 카운트\n",
    "    if len(points_gdf) > 0:\n",
    "        jj = gpd.sjoin(emd, points_gdf[[\"geometry\"]], how=\"left\", predicate=\"contains\")\n",
    "        counts = jj.groupby(jj.index).size().reindex(emd.index).fillna(0).astype(int)\n",
    "    else:\n",
    "        counts = pd.Series(0, index=emd.index, dtype=int)\n",
    "    out = pd.DataFrame(index=emd.index)\n",
    "    out[f\"{prefix}_count\"] = counts\n",
    "    area = (emd.geometry.area/1_000_000.0).replace(0, np.nan)\n",
    "    out[f\"{prefix}_dens_km2\"] = out[f\"{prefix}_count\"] / area\n",
    "    out[f\"{prefix}_dens_log1p\"] = np.log1p(out[f\"{prefix}_dens_km2\"])\n",
    "    out = pd.concat([out, near], axis=1)\n",
    "    out[f\"{prefix}_nearest_km\"] = out[f\"{prefix}_nearest_m\"] / 1000.0\n",
    "    out[f\"{prefix}_nearest_log1p\"] = np.log1p(out[f\"{prefix}_nearest_km\"])\n",
    "    return out\n",
    "\n",
    "def zscore(s: pd.Series):\n",
    "    return (s - s.mean()) / (s.std(ddof=0) + 1e-9)\n",
    "\n",
    "def read_any_table(p: Path) -> pd.DataFrame:\n",
    "    if p.suffix.lower() == \".csv\":\n",
    "        for enc in (\"utf-8-sig\",\"cp949\",\"euc-kr\"):\n",
    "            try: return pd.read_csv(p, encoding=enc)\n",
    "            except UnicodeDecodeError: continue\n",
    "        return pd.read_csv(p)\n",
    "    else:\n",
    "        return pd.read_excel(p)\n",
    "\n",
    "def find_pop_files(pop_dir: Path):\n",
    "    pats=[r\".*인구.*\\.(csv|xlsx)$\", r\".*주민.*\\.(csv|xlsx)$\", r\".*세대.*\\.(csv|xlsx)$\"]\n",
    "    files=[]\n",
    "    for fp in pop_dir.glob(\"**/*\"):\n",
    "        if fp.is_file() and any(re.match(p, fp.name, flags=re.I) for p in pats):\n",
    "            files.append(fp)\n",
    "    return files\n",
    "\n",
    "def coerce_ym(s):\n",
    "    if pd.isna(s): return (None,None)\n",
    "    t=str(s).strip().replace(\".\",\"\").replace(\"-\",\"\").replace(\"/\",\"\")\n",
    "    if len(t)>=6 and t[:6].isdigit(): return (int(t[:4]), int(t[4:6]))\n",
    "    if len(t)==4 and t.isdigit(): return (int(t),12)\n",
    "    return (None,None)\n",
    "\n",
    "def resolve_keys_from_pop(df_in: pd.DataFrame):\n",
    "    \"\"\"인구 표에서 이름/코드 표준 키 생성(없으면 패턴으로 이름 유추)\"\"\"\n",
    "    df = df_in.copy()\n",
    "    code_col = pick_col(df.columns, POP_CODE_CANDS)\n",
    "    name_col = pick_col(df.columns, POP_NAME_CANDS)\n",
    "    if code_col is not None:\n",
    "        df[\"ADM_CODE_STD\"] = normalize_adm_code(df[code_col])\n",
    "    if name_col is not None:\n",
    "        df[\"EMD_NAME_STD\"] = df[name_col].astype(str).map(standardize_emd_name)\n",
    "    if (\"ADM_CODE_STD\" not in df.columns) and (\"EMD_NAME_STD\" not in df.columns):\n",
    "        # 값 패턴으로 이름 추정\n",
    "        for c in df.columns:\n",
    "            if df[c].dtype == \"object\":\n",
    "                s = df[c].astype(str).head(200)\n",
    "                if s.str.contains(r\"(동|읍|면|리)$\").mean() >= 0.2:\n",
    "                    df[\"EMD_NAME_STD\"] = df[c].astype(str).map(standardize_emd_name)\n",
    "                    break\n",
    "    return df\n",
    "\n",
    "def pick_pop_value_cols(df: pd.DataFrame):\n",
    "    total = pick_col(df.columns, [\"총인구\",\"인구\",\"총인구수\",\"population\",\"total_pop\"])\n",
    "    aged  = pick_col(df.columns, [\"65세이상\",\"65세이상인구\",\"고령인구\",\"over65\"])\n",
    "    aging = pick_col(df.columns, [\"고령화율\",\"aging_rate\",\"65세이상비율\",\"ratio_65\"])\n",
    "    return total, aged, aging\n",
    "\n",
    "# ===== 인구 로더 (A) 폴더 스캔 버전 =====\n",
    "def build_population_from_dir(pop_dir: Path, years: list):\n",
    "    files = find_pop_files(pop_dir)\n",
    "    if not files:\n",
    "        print(f\"[WARN] 인구 파일이 없습니다: {pop_dir}\")\n",
    "        return pd.DataFrame()\n",
    "    frames=[]\n",
    "    for p in files:\n",
    "        df = read_any_table(p)\n",
    "        df = resolve_keys_from_pop(df)\n",
    "        ym_col = pick_col(df.columns, [\"기준년월\",\"년월\",\"연월\",\"yyyymm\",\"기준일자\",\"date\",\"집계년월\"])\n",
    "        year_col = pick_col(df.columns, [\"연도\",\"년도\",\"year\",\"Year\"])\n",
    "        month_col= pick_col(df.columns, [\"월\",\"month\",\"Month\"])\n",
    "        if ym_col:\n",
    "            ym=df[ym_col].map(coerce_ym); df[\"__year__\"]=[y for y,_ in ym]; df[\"__month__\"]=[m for _,m in ym]\n",
    "        elif year_col:\n",
    "            df[\"__year__\"]=pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "            df[\"__month__\"]=pd.to_numeric(df[month_col], errors=\"coerce\") if month_col else 12\n",
    "        else:\n",
    "            m=re.search(r\"(20\\d{2})(0[1-9]|1[0-2])\", p.stem)\n",
    "            if m: df[\"__year__\"]=int(m.group(1)); df[\"__month__\"]=int(m.group(2))\n",
    "            else:\n",
    "                m2=re.search(r\"(20\\d{2})\", p.stem)\n",
    "                df[\"__year__\"]=int(m2.group(1)) if m2 else np.nan; df[\"__month__\"]=12\n",
    "        total, aged, aging = pick_pop_value_cols(df)\n",
    "        keep = [\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\",\"__month__\"] + [c for c in [total, aged, aging] if c]\n",
    "        frames.append(df[keep].copy())\n",
    "\n",
    "    pop = pd.concat(frames, ignore_index=True)\n",
    "    pop = pop.dropna(subset=[\"__year__\"])\n",
    "    pop = pop[pop[\"__year__\"].isin(years)]\n",
    "    pop = pop.sort_values([\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\",\"__month__\"])\n",
    "    pop = pop.groupby([\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\"], as_index=False).tail(1)\n",
    "\n",
    "    if \"aging_rate\" not in pop.columns:\n",
    "        tcol, acol = pick_col(pop.columns, [\"총인구\",\"인구\",\"총인구수\",\"population\",\"total_pop\"]), pick_col(pop.columns, [\"65세이상\",\"65세이상인구\",\"고령인구\",\"over65\"])\n",
    "        if tcol and acol:\n",
    "            pop[\"aging_rate\"] = pd.to_numeric(pop[acol], errors=\"coerce\")/pd.to_numeric(pop[tcol], errors=\"coerce\")\n",
    "    pop = pop.rename(columns={\"__year__\":\"year\"})\n",
    "    return pop\n",
    "\n",
    "# ===== 인구 로더 (B) 단일 CSV 버전 =====\n",
    "def build_population_from_single_csv(pop_file: Path, years: list) -> pd.DataFrame:\n",
    "    df = read_any_table(pop_file)\n",
    "    df = resolve_keys_from_pop(df)\n",
    "\n",
    "    # (선택) 지역 필터: 충청남도 & 천안시 동남구/서북구에 한정\n",
    "    sido_col = pick_col(df.columns, SIDO_CANDS)\n",
    "    sig_col  = pick_col(df.columns, SIG_CANDS)\n",
    "    if sido_col is not None:\n",
    "        df = df[df[sido_col].astype(str).str.contains(\"충청남도\", na=False)]\n",
    "    if sig_col is not None:\n",
    "        df = df[df[sig_col].astype(str).isin([\"천안시 동남구\",\"천안시 서북구\"])]\n",
    "\n",
    "    ym_col    = pick_col(df.columns, [\"기준년월\",\"년월\",\"연월\",\"yyyymm\",\"기준일자\",\"date\",\"집계년월\"])\n",
    "    year_col  = pick_col(df.columns, [\"연도\",\"년도\",\"year\",\"Year\"])\n",
    "    month_col = pick_col(df.columns, [\"월\",\"month\",\"Month\"])\n",
    "    if ym_col:\n",
    "        ym=df[ym_col].map(coerce_ym); df[\"__year__\"]=[y for y,_ in ym]; df[\"__month__\"]=[m for _,m in ym]\n",
    "    elif year_col:\n",
    "        df[\"__year__\"]=pd.to_numeric(df[year_col], errors=\"coerce\")\n",
    "        df[\"__month__\"]=pd.to_numeric(df[month_col], errors=\"coerce\") if month_col else 12\n",
    "    else:\n",
    "        m=re.search(r\"(20\\d{2})(0[1-9]|1[0-2])\", pop_file.stem)\n",
    "        if m: df[\"__year__\"]=int(m.group(1)); df[\"__month__\"]=int(m.group(2))\n",
    "        else:\n",
    "            m2=re.search(r\"(20\\d{2})\", pop_file.stem)\n",
    "            df[\"__year__\"]=int(m2.group(1)) if m2 else np.nan; df[\"__month__\"]=12\n",
    "\n",
    "    total, aged, aging = pick_pop_value_cols(df)\n",
    "    has_emd = (\"EMD_NAME_STD\" in df.columns and df[\"EMD_NAME_STD\"].notna().any()) or \\\n",
    "              (\"ADM_CODE_STD\" in df.columns and df[\"ADM_CODE_STD\"].str.len().fillna(0).astype(int).ge(8).any())\n",
    "\n",
    "    df = df.dropna(subset=[\"__year__\"])\n",
    "    df = df[df[\"__year__\"].isin(years)]\n",
    "    df = df.sort_values([\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\",\"__month__\"])\n",
    "\n",
    "    if has_emd:\n",
    "        keep = [c for c in [\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\",\"__month__\", total, aged, aging] if c]\n",
    "        part = df[keep].copy()\n",
    "        part = part.groupby([\"ADM_CODE_STD\",\"EMD_NAME_STD\",\"__year__\"], as_index=False).tail(1)\n",
    "        if (aging is None) and total and aged:\n",
    "            part[\"aging_rate\"] = pd.to_numeric(part[aged], errors=\"coerce\") / pd.to_numeric(part[total], errors=\"coerce\")\n",
    "        part = part.rename(columns={\"__year__\":\"year\"})\n",
    "        return part\n",
    "    else:\n",
    "        raise SystemExit(\"단일 CSV가 시군구 수준으로 보입니다. EMD 레벨 키가 없어 EMD 모델에 곧바로 쓸 수 없습니다.\")\n",
    "\n",
    "# ================== 데이터 로드/피처 구성 ==================\n",
    "print(\"[INFO] 1) EMD 경계 읽기 & 키 생성\")\n",
    "emd = resolve_emd_keys_from_shp(str(SHP_PATH))\n",
    "BOUNDARY_HAS_CODE = \"ADM_CODE_STD\" in emd.columns\n",
    "BOUNDARY_HAS_NAME = \"EMD_NAME_STD\" in emd.columns\n",
    "idx_col = \"EMD_NAME_STD\" if BOUNDARY_HAS_NAME else \"ADM_CODE_STD\"\n",
    "emd = emd.set_index(idx_col, drop=False)\n",
    "\n",
    "print(\"[INFO] 2) POI 읽기 → 포인트 변환 → 경계 좌표계로 투영\")\n",
    "def read_poi(csv_path: Path, emd):\n",
    "    if not csv_path.exists():\n",
    "        print(f\"[WARN] POI 파일 없음: {csv_path.name}\")\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    try: df = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "    except UnicodeDecodeError: df = pd.read_csv(csv_path, encoding=\"cp949\")\n",
    "    lat, lon = detect_latlon(df)\n",
    "    if not (lat and lon):\n",
    "        print(f\"[WARN] 위경도 컬럼 자동탐색 실패 → 빈 처리: {csv_path.name}\")\n",
    "        return gpd.GeoDataFrame(geometry=[], crs=\"EPSG:4326\")\n",
    "    g = to_points(df, lat, lon, crs=\"EPSG:4326\")\n",
    "    return project_like(g, emd)\n",
    "\n",
    "g_school = read_poi(SCHOOL_CSV, emd)\n",
    "g_bus    = read_poi(BUS_CSV, emd)\n",
    "g_hosp   = read_poi(HOSPITAL_CSV, emd)\n",
    "\n",
    "print(\"[INFO] 3) EMD별 정적 피처(카운트/밀도/최근접거리) + 합성지표\")\n",
    "f_school = sjoin_counts_and_nearest(g_school, emd, \"school\")\n",
    "f_bus    = sjoin_counts_and_nearest(g_bus, emd, \"bus\")\n",
    "f_hosp   = sjoin_counts_and_nearest(g_hosp, emd, \"hosp\")\n",
    "feat_static = pd.concat([f_school, f_bus, f_hosp], axis=1)\n",
    "\n",
    "feat_static[\"school_z\"] = zscore(feat_static[\"school_dens_km2\"].fillna(0))\n",
    "feat_static[\"bus_z\"]    = zscore(feat_static[\"bus_dens_km2\"].fillna(0))\n",
    "feat_static[\"hosp_z\"]   = zscore(feat_static[\"hosp_dens_km2\"].fillna(0))\n",
    "\n",
    "# 합성지표(도메인 priors)\n",
    "feat_static[\"YouthIndex\"]      = 0.5*feat_static[\"school_z\"] + 0.3*feat_static[\"bus_z\"] + 0.2*feat_static[\"hosp_z\"]\n",
    "feat_static[\"SeniorCareIndex\"] = 0.6*feat_static[\"hosp_z\"]  + 0.3*feat_static[\"bus_z\"] + 0.1*feat_static[\"school_z\"]\n",
    "feat_static[\"area_km2\"] = emd[\"area_km2\"]\n",
    "\n",
    "print(\"[INFO] 4) 인구 표 읽기/연도화\")\n",
    "if POP_INPUT_IS_FILE:\n",
    "    pop_yearly = build_population_from_single_csv(POP_FILE, YEARS)\n",
    "else:\n",
    "    pop_yearly = build_population_from_dir(POP_DIR, YEARS)\n",
    "\n",
    "if pop_yearly.empty:\n",
    "    raise SystemExit(\"[ERROR] 인구 데이터가 비었습니다. POP 입력을 확인하세요.\")\n",
    "\n",
    "print(\"[INFO] 5) 연패널 구성(정적 피처 연도별 복제) + 병합\")\n",
    "panel=[]\n",
    "for y in YEARS:\n",
    "    tmp = feat_static.copy()\n",
    "    tmp[\"year\"] = y\n",
    "    if \"EMD_NAME_STD\" in emd.columns: tmp[\"EMD_NAME_STD\"] = emd[\"EMD_NAME_STD\"]\n",
    "    if \"ADM_CODE_STD\" in emd.columns: tmp[\"ADM_CODE_STD\"] = emd[\"ADM_CODE_STD\"]\n",
    "    panel.append(tmp.reset_index(drop=True))\n",
    "panel = pd.concat(panel, axis=0)\n",
    "\n",
    "# 병합 키 결정 (코드 우선, 그다음 이름)\n",
    "POP_HAS_CODE = \"ADM_CODE_STD\" in pop_yearly.columns\n",
    "POP_HAS_NAME = \"EMD_NAME_STD\" in pop_yearly.columns\n",
    "BOUNDARY_HAS_CODE = \"ADM_CODE_STD\" in panel.columns\n",
    "BOUNDARY_HAS_NAME = \"EMD_NAME_STD\" in panel.columns\n",
    "\n",
    "if BOUNDARY_HAS_CODE and POP_HAS_CODE:\n",
    "    key = \"ADM_CODE_STD\"\n",
    "elif BOUNDARY_HAS_NAME and POP_HAS_NAME:\n",
    "    key = \"EMD_NAME_STD\"\n",
    "else:\n",
    "    key = \"EMD_NAME_STD\" if POP_HAS_NAME else \"ADM_CODE_STD\"\n",
    "\n",
    "data = pop_yearly.merge(panel, on=[key,\"year\"], how=\"left\")\n",
    "\n",
    "# ================== 타깃/피처(X, y, groups) ==================\n",
    "tgt=None\n",
    "for c in TARGET_CANDIDATES:\n",
    "    if c in data.columns:\n",
    "        tgt=c; break\n",
    "if tgt is None:\n",
    "    raise SystemExit(\"[ERROR] 타깃 컬럼(고령화율/총인구 등)이 데이터에 없습니다.\")\n",
    "\n",
    "feature_cols = [\n",
    "    \"school_dens_km2\",\"bus_dens_km2\",\"hosp_dens_km2\",\n",
    "    \"school_dens_log1p\",\"bus_dens_log1p\",\"hosp_dens_log1p\",\n",
    "    \"school_nearest_km\",\"bus_nearest_km\",\"hosp_nearest_km\",\n",
    "    \"school_nearest_log1p\",\"bus_nearest_log1p\",\"hosp_nearest_log1p\",\n",
    "    \"YouthIndex\",\"SeniorCareIndex\",\"area_km2\",\n",
    "]\n",
    "feature_cols = [c for c in feature_cols if c in data.columns]\n",
    "for c in feature_cols:\n",
    "    data[c] = pd.to_numeric(data[c], errors=\"coerce\").fillna(0)\n",
    "\n",
    "y_all = pd.to_numeric(data[tgt], errors=\"coerce\")\n",
    "mask = ~y_all.isna()\n",
    "data = data.loc[mask].reset_index(drop=True)\n",
    "y_all = y_all.loc[mask].reset_index(drop=True)\n",
    "X_all = data[feature_cols].copy()\n",
    "years_col = data[\"year\"].astype(int)\n",
    "\n",
    "print(f\"[INFO] Target={tgt} | X={X_all.shape} | Years={sorted(years_col.unique())}\")\n",
    "print(\"[DEBUG] Features:\", feature_cols)\n",
    "\n",
    "# ================== 3:1:1 연도 분리 함수 ==================\n",
    "def split_years_3_1_1(years_sorted):\n",
    "    \"\"\"\n",
    "    years_sorted: 정렬된 유니크 연도 리스트\n",
    "    3:1:1 비율로 (Train, Valid, Test) 연도 집합을 반환.\n",
    "    예) [2020,2021,2022,2023,2024] → (2020~2022, 2023, 2024)\n",
    "    \"\"\"\n",
    "    k = len(years_sorted)\n",
    "    if k < 3:\n",
    "        # 연도가 3개 미만이면 보수적 분리\n",
    "        if k == 2:\n",
    "            return years_sorted[:1], [years_sorted[1]], []   # Train=첫해, Valid=둘째해, Test=없음(경고)\n",
    "        elif k == 1:\n",
    "            return [years_sorted[0]], [], []                 # 전부 Train\n",
    "        else:\n",
    "            return [], [], []\n",
    "    # 60/20/20 할당 (반올림 대신 고정 규칙: 앞 60%, 다음 20%, 끝 20%)\n",
    "    n_train = max(1, int(round(k * 0.6)))\n",
    "    n_valid = max(1, int(round(k * 0.2)))\n",
    "    # 합이 k를 초과/미만할 수 있어 보정\n",
    "    if n_train + n_valid > k - 1:         # 최소 1년은 test 확보\n",
    "        n_valid = max(1, k - n_train - 1)\n",
    "    n_test = k - n_train - n_valid\n",
    "    if n_test == 0:                        # 그래도 0이면 train에서 1년 빼서 test로\n",
    "        n_train = max(1, n_train - 1); n_test = 1\n",
    "    train_years = years_sorted[:n_train]\n",
    "    valid_years = years_sorted[n_train:n_train+n_valid]\n",
    "    test_years  = years_sorted[n_train+n_valid:]\n",
    "    return train_years, valid_years, test_years\n",
    "\n",
    "years_sorted = sorted(years_col.unique().tolist())\n",
    "train_years, valid_years, test_years = split_years_3_1_1(years_sorted)\n",
    "\n",
    "print(f\"[INFO] Split years → Train={train_years} | Valid={valid_years} | Test={test_years}\")\n",
    "\n",
    "tr_mask = years_col.isin(train_years)\n",
    "va_mask = years_col.isin(valid_years)\n",
    "te_mask = years_col.isin(test_years)\n",
    "\n",
    "X_tr, y_tr = X_all[tr_mask], y_all[tr_mask]\n",
    "X_va, y_va = X_all[va_mask], y_all[va_mask]\n",
    "X_te, y_te = X_all[te_mask], y_all[te_mask]\n",
    "\n",
    "# ================== LightGBM 설정 ==================\n",
    "lgbm_val = LGBMRegressor(\n",
    "    n_estimators=1600,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    max_depth=-1,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_alpha=1e-2,\n",
    "    reg_lambda=1e-1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ---------- 1) Train → Valid 성능 ----------\n",
    "print(\"[INFO] Fit on TRAIN → evaluate on VALID\")\n",
    "lgbm_val.fit(X_tr, y_tr)\n",
    "pred_va = lgbm_val.predict(X_va)\n",
    "\n",
    "va_r2   = r2_score(y_va, pred_va) if len(y_va)>0 else np.nan\n",
    "va_mae  = mean_absolute_error(y_va, pred_va) if len(y_va)>0 else np.nan\n",
    "va_rmse = mean_squared_error(y_va, pred_va, squared=False) if len(y_va)>0 else np.nan\n",
    "print(f\"[VALID] R2={va_r2:.4f}  MAE={va_mae:.4f}  RMSE={va_rmse:.4f}\")\n",
    "\n",
    "# ---------- 2) Train+Valid → Test 성능 ----------\n",
    "print(\"[INFO] Fit on TRAIN+VALID → evaluate on TEST\")\n",
    "X_trva = pd.concat([X_tr, X_va], axis=0)\n",
    "y_trva = pd.concat([y_tr, y_va], axis=0)\n",
    "\n",
    "lgbm_test = LGBMRegressor(\n",
    "    n_estimators=1800,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    max_depth=-1,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_alpha=1e-2,\n",
    "    reg_lambda=1e-1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lgbm_test.fit(X_trva, y_trva)\n",
    "pred_te = lgbm_test.predict(X_te)\n",
    "\n",
    "te_r2   = r2_score(y_te, pred_te) if len(y_te)>0 else np.nan\n",
    "te_mae  = mean_absolute_error(y_te, pred_te) if len(y_te)>0 else np.nan\n",
    "te_rmse = mean_squared_error(y_te, pred_te, squared=False) if len(y_te)>0 else np.nan\n",
    "print(f\"[TEST]  R2={te_r2:.4f}  MAE={te_mae:.4f}  RMSE={te_rmse:.4f}\")\n",
    "\n",
    "# ================== 결과 저장 ==================\n",
    "# 1) 메트릭 저장\n",
    "metrics = pd.DataFrame([\n",
    "    {\"split\":\"valid\",\"R2\":va_r2,\"MAE\":va_mae,\"RMSE\":va_rmse,\"years\":\",\".join(map(str,valid_years))},\n",
    "    {\"split\":\"test\",\"R2\":te_r2,\"MAE\":te_mae,\"RMSE\":te_rmse,\"years\":\",\".join(map(str,test_years))}\n",
    "])\n",
    "metrics.to_csv(OUT/\"metrics_lgbm_3_1_1.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 2) 중요도 (Permutation: VALID 기준, 내장 중요도: Train+Valid 모델)\n",
    "try:\n",
    "    if len(y_va)>0:\n",
    "        imp_perm = permutation_importance(lgbm_val, X_va, y_va, n_repeats=10, random_state=RANDOM_STATE)\n",
    "        pd.DataFrame({\"feature\":X_va.columns,\n",
    "                      \"perm_importance_mean\":imp_perm.importances_mean,\n",
    "                      \"perm_importance_std\":imp_perm.importances_std})\\\n",
    "          .sort_values(\"perm_importance_mean\", ascending=False)\\\n",
    "          .to_csv(OUT/\"feat_importance_perm_VALID.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "except Exception as e:\n",
    "    print(\"[WARN] VALID permutation importance 실패:\", e)\n",
    "\n",
    "try:\n",
    "    fi = getattr(lgbm_test, \"feature_importances_\", None)\n",
    "    if fi is not None:\n",
    "        pd.DataFrame({\"feature\":X_trva.columns, \"lgbm_importance\":fi})\\\n",
    "          .sort_values(\"lgbm_importance\", ascending=False)\\\n",
    "          .to_csv(OUT/\"feat_importance_lgbm_train_valid.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "except Exception as e:\n",
    "    print(\"[WARN] 내장 중요도 저장 실패:\", e)\n",
    "\n",
    "# 3) 예측 저장\n",
    "pred_df = pd.DataFrame({\n",
    "    \"EMD_NAME_STD\": data[\"EMD_NAME_STD\"] if \"EMD_NAME_STD\" in data.columns else np.nan,\n",
    "    \"ADM_CODE_STD\": data[\"ADM_CODE_STD\"] if \"ADM_CODE_STD\" in data.columns else np.nan,\n",
    "    \"year\": years_col,\n",
    "    \"split\": np.where(tr_mask, \"train\", np.where(va_mask, \"valid\", np.where(te_mask, \"test\", \"unused\"))),\n",
    "    \"y_true\": y_all\n",
    "})\n",
    "\n",
    "# 분할별 예측\n",
    "pred_df.loc[va_mask,  \"y_pred\"] = pred_va\n",
    "pred_df.loc[te_mask,  \"y_pred\"] = pred_te\n",
    "# (train 예측이 필요하면 아래 두 줄 주석 해제)\n",
    "# pred_df.loc[tr_mask,  \"y_pred\"] = lgbm_val.predict(X_tr)\n",
    "\n",
    "pred_df.to_csv(OUT/\"predictions_by_split.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# 4) 최종 모델 저장 (Train+Valid 전체로 학습된 모델)\n",
    "joblib.dump(lgbm_test, OUT/\"final_lgbm_train_valid.pkl\")\n",
    "\n",
    "# 5) 재현성용 입력 패널 저장\n",
    "panel_cols = [c for c in [\"EMD_NAME_STD\",\"ADM_CODE_STD\",\"year\",tgt]+feature_cols if c in data.columns]\n",
    "data[panel_cols].to_csv(OUT/\"model_input_panel.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"[DONE] outputs →\", OUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cheonan .venv)",
   "language": "python",
   "name": "cheonan-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
